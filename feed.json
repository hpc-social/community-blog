{
    "version": "https://jsonfeed.org/version/1",
    "title": "hpc.social - Community Syndicated Blog",
    "home_page_url": "https://hpc.social/community-blog/",
    "feed_url": "https://hpc.social/community-blog/feed.json",
    "description": "Shared community experiences and stories",
    "icon": "https://hpc.social/community-blog/assets/images/apple-touch-icon.png",
    "favicon": "https://hpc.social/community-blog/assets/images/favicon.png",
    "expired": false,
    
    "author":  {
        "name": "hpc.social",
        "url": null,
        "avatar": null
    },
    
"items": [
    
        {
            "id": "https://hpc.social/community-blog/2026/new-board-members-van-der-pas-and-stotzer/",
            "title": "New Board Members van der Pas and Stotzer",
            "summary": null,
            "content_text": "The OpenMP ARB welcomes Ruud van der Pas and Eric Stotzer to its Board of Directors.The post New Board Members van der Pas and Stotzer appeared first on OpenMP.",
            "content_html": "<p>The OpenMP ARB welcomes Ruud van der Pas and Eric Stotzer to its Board of Directors.</p><p>The post <a href=\"https://www.openmp.org/press-release/board-stotzer-vdpas/\">New Board Members van der Pas and Stotzer</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2026/new-board-members-van-der-pas-and-stotzer/",
            
            
            
            
            
            "date_published": "2026-02-16T18:44:35-07:00",
            "date_modified": "2026-02-16T18:44:35-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2026/openmp-example-book-survey/",
            "title": "OpenMP Example Book Survey",
            "summary": null,
            "content_text": "If you have used our OpenMP API Examples book, take our survey to tell us how we can improve it.The post OpenMP Example Book Survey appeared first on OpenMP.",
            "content_html": "<p>If you have used our OpenMP API Examples book, take our survey to tell us how we can improve it.</p><p>The post <a href=\"https://www.openmp.org/2026/openmp-example-book-survey/\">OpenMP Example Book Survey</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2026/openmp-example-book-survey/",
            
            
            
            
            
            "date_published": "2026-02-15T18:47:18-07:00",
            "date_modified": "2026-02-15T18:47:18-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2026/new-python-subcommittee-and-anaconda-joins-openmp-arb/",
            "title": "New Python Subcommittee, and Anaconda joins OpenMP ARB",
            "summary": null,
            "content_text": "Anaconda has joined the OpenMP ARB, and the OpenMP ARB has formed a new Python subcommittee to add Python as the fourth supported language in the OpenMP API.The post New Python Subcommittee, and Anaconda joins OpenMP ARB appeared first on OpenMP.",
            "content_html": "<p>Anaconda has joined the OpenMP ARB, and the OpenMP ARB has formed a new Python subcommittee to add Python as the fourth supported language in the OpenMP API.</p><p>The post <a href=\"https://www.openmp.org/press-release/python-new-member-anaconda/\">New Python Subcommittee, and Anaconda joins OpenMP ARB</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2026/new-python-subcommittee-and-anaconda-joins-openmp-arb/",
            
            
            
            
            
            "date_published": "2026-02-04T21:00:28-07:00",
            "date_modified": "2026-02-04T21:00:28-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2026/iwomp-2026/",
            "title": "IWOMP 2026",
            "summary": null,
            "content_text": "IWOMP 2026 Join us for IWOMP 2026 at Austrian Scientific Computing (ASC) at TU Wien in Vienna (Austria)The post IWOMP 2026 appeared first on OpenMP.",
            "content_html": "<p>IWOMP 2026 Join us for IWOMP 2026 at Austrian Scientific Computing (ASC) at TU Wien in Vienna (Austria)</p><p>The post <a href=\"https://www.openmp.org/events/iwomp-2026/\">IWOMP 2026</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2026/iwomp-2026/",
            
            
            
            
            
            "date_published": "2026-01-28T17:11:06-07:00",
            "date_modified": "2026-01-28T17:11:06-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/openmp-arb-releases-technical-report-14/",
            "title": "OpenMP ARB Releases Technical Report 14",
            "summary": null,
            "content_text": "The OpenMP® ARB has released Technical Report 14, a preview of version 6.1 of the OpenMP API, which will be released in 2026.The post OpenMP ARB Releases Technical Report 14 appeared first on OpenMP.",
            "content_html": "<p>The OpenMP® ARB has released Technical Report 14, a preview of version 6.1 of the OpenMP API, which will be released in 2026.</p><p>The post <a href=\"https://www.openmp.org/press-release/openmp-arb-releases-tr14/\">OpenMP ARB Releases Technical Report 14</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/openmp-arb-releases-technical-report-14/",
            
            
            
            
            
            "date_published": "2025-11-13T15:53:14-07:00",
            "date_modified": "2025-11-13T15:53:14-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/supercomputing-2025/",
            "title": "Supercomputing 2025",
            "summary": null,
            "content_text": "November 2025Visit us in booth 911, attend our BOF, and attend our two tutorials at SC25 in St. Louis. See videos and more.The post Supercomputing 2025 appeared first on OpenMP.",
            "content_html": "<p>November 2025<br />Visit us in booth 911, attend our BOF, and attend our two tutorials at SC25 in St. Louis. See videos and more.</p><p>The post <a href=\"https://www.openmp.org/events/sc25/\">Supercomputing 2025</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/supercomputing-2025/",
            
            
            
            
            
            "date_published": "2025-07-29T15:28:58-06:00",
            "date_modified": "2025-07-29T15:28:58-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/iwomp-2025/",
            "title": "IWOMP 2025",
            "summary": null,
            "content_text": "IWOMP 2025 will be held at the UNC Charlotte campus in North Carolina, Oct 1 – Oct. 3, 2025.The post IWOMP 2025 appeared first on OpenMP.",
            "content_html": "<p>IWOMP 2025 will be held at the UNC Charlotte campus in North Carolina, Oct 1 – Oct. 3, 2025.</p><p>The post <a href=\"https://www.openmp.org/events/iwomp-2025/\">IWOMP 2025</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/iwomp-2025/",
            
            
            
            
            
            "date_published": "2025-07-15T00:48:20-06:00",
            "date_modified": "2025-07-15T00:48:20-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/nextsilicon-joins-the-openmp/",
            "title": "NextSilicon joins the OpenMP",
            "summary": null,
            "content_text": "June 10, 2025 — NextSilicon has joined the OpenMP ARB, a group of leading hardware and software vendors and research organizations creating the standard for the most popular shared-memory parallel programming model in use today.The post NextSilicon joins the OpenMP appeared first on OpenMP.",
            "content_html": "<p>June 10, 2025 — NextSilicon has joined the OpenMP ARB, a group of leading hardware and software vendors and research organizations creating the standard for the most popular shared-memory parallel programming model in use today.</p><p>The post <a href=\"https://www.openmp.org/press-release/new-member-nextsilicon/\">NextSilicon joins the OpenMP</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/nextsilicon-joins-the-openmp/",
            
            
            
            
            
            "date_published": "2025-06-10T10:00:58-06:00",
            "date_modified": "2025-06-10T10:00:58-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/isc-2025/",
            "title": "ISC 2025",
            "summary": null,
            "content_text": "ISC 2025 will be held in Hamburg, Germany June 10-13, bringing together over 3,500 international attendees to exchange ideas and knowledge.The post ISC 2025 appeared first on OpenMP.",
            "content_html": "<p>ISC 2025 will be held in Hamburg, Germany June 10-13, bringing together over 3,500 international attendees to exchange ideas and knowledge.</p><p>The post <a href=\"https://www.openmp.org/events/isc2025/\">ISC 2025</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/isc-2025/",
            
            
            
            
            
            "date_published": "2025-02-28T20:12:17-07:00",
            "date_modified": "2025-02-28T20:12:17-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/status-of-openmp-api-6-0-implementations/",
            "title": "Status of OpenMP API 6.0 Implementations",
            "summary": null,
            "content_text": "First implementations of OpenMP 6.0 features are now available in Intel® and GCC compilers.The post Status of OpenMP API 6.0 Implementations appeared first on OpenMP.",
            "content_html": "<p>First implementations of OpenMP 6.0 features are now available in Intel® and GCC compilers.</p><p>The post <a href=\"https://www.openmp.org/blog/openmp-6/\">Status of OpenMP API 6.0 Implementations</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/status-of-openmp-api-6-0-implementations/",
            
            
            
            
            
            "date_published": "2025-02-25T10:00:35-07:00",
            "date_modified": "2025-02-25T10:00:35-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2025/iwomp-2025/",
            "title": "IWOMP 2025",
            "summary": null,
            "content_text": "IWOMP 2025  will be held at the UNC Charlotte campus in North Carolina, US.The post IWOMP 2025 appeared first on OpenMP.",
            "content_html": "<p>IWOMP 2025  will be held at the UNC Charlotte campus in North Carolina, US.</p><p>The post <a href=\"https://www.openmp.org/events/iwomp-2024-2/\">IWOMP 2025</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2025/iwomp-2025/",
            
            
            
            
            
            "date_published": "2025-02-15T00:48:20-07:00",
            "date_modified": "2025-02-15T00:48:20-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2024/openmp-arb-releases-openmp-6-0-for-easier-programming/",
            "title": "OpenMP® ARB Releases OpenMP 6.0 for Easier Programming",
            "summary": null,
            "content_text": "Develop Parallel Programs Easily and More Control to Developers SC24, Atlanta, Georgia – November 14, 2024 – The OpenMP Architecture Review Board (ARB) is pleased to announce Version 6.0 of the OpenMP API Specification, a major upgrade of the OpenMP language. This new version opens up parallel programming to new applications, makes it easier to  [...]The post OpenMP® ARB Releases OpenMP 6.0 for Easier Programming appeared first on OpenMP.",
            "content_html": "<p>Develop Parallel Programs Easily and More Control to Developers SC24, Atlanta, Georgia – November 14, 2024 – The OpenMP Architecture Review Board (ARB) is pleased to announce Version 6.0 of the OpenMP API Specification, a major upgrade of the OpenMP language. This new version opens up parallel programming to new applications, makes it easier to  [...]</p><p>The post <a href=\"https://www.openmp.org/home-news/openmp-arb-releases-openmp-6-0-for-easier-programming/\">OpenMP® ARB Releases OpenMP 6.0 for Easier Programming</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2024/openmp-arb-releases-openmp-6-0-for-easier-programming/",
            
            
            
            
            
            "date_published": "2024-11-14T18:00:41-07:00",
            "date_modified": "2024-11-14T18:00:41-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2024/supercomputing-2024/",
            "title": "Supercomputing 2024",
            "summary": null,
            "content_text": "November 18, 2024OpenMP will be in Atlanta for Supercomputing 2024 with two tutorials, a BOF, and much more.The post Supercomputing 2024 appeared first on OpenMP.",
            "content_html": "<p>November 18, 2024<br />OpenMP will be in Atlanta for Supercomputing 2024 with two tutorials, a BOF, and much more.</p><p>The post <a href=\"https://www.openmp.org/events/sc24/\">Supercomputing 2024</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2024/supercomputing-2024/",
            
            
            
            
            
            "date_published": "2024-08-27T23:13:58-06:00",
            "date_modified": "2024-08-27T23:13:58-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2024/openmp-arb-releases-public-comment-draft-of-openmp-6-0/",
            "title": "OpenMP ARB Releases Public Comment Draft of OpenMP 6.0",
            "summary": null,
            "content_text": "The OpenMP® Architecture Review Board (ARB) has released Technical Report 13: the final public comment draft of version 6.0 of the OpenMP API. Version 6.0 of the OpenMP API will be released in November 2024.The post OpenMP ARB Releases Public Comment Draft of OpenMP 6.0 appeared first on OpenMP.",
            "content_html": "<p>The OpenMP® Architecture Review Board (ARB) has released Technical Report 13: the final public comment draft of version 6.0 of the OpenMP API. Version 6.0 of the OpenMP API will be released in November 2024.</p><p>The post <a href=\"https://www.openmp.org/home-news/openmp-arb-releases-public-comment-draft-of-openmp-6-0/\">OpenMP ARB Releases Public Comment Draft of OpenMP 6.0</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2024/openmp-arb-releases-public-comment-draft-of-openmp-6-0/",
            
            
            
            
            
            "date_published": "2024-08-01T15:54:15-06:00",
            "date_modified": "2024-08-01T15:54:15-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2024/asynchronous-gpu-programming-in-openmp/",
            "title": "Asynchronous GPU Programming in OpenMP",
            "summary": null,
            "content_text": "The Centre of Excellence on Performance Optimisation and Productivity published the recording of a webinar on Asynchronous GPU Programming in OpenMP where Christian Terboven and Michael Klemm discuss the optimization of data transfers and asynchronous offloading, hybrid OpenMP and HIP, and advanced task synchronization. Watch now.The post Asynchronous GPU Programming in OpenMP appeared first on OpenMP.",
            "content_html": "<p>The Centre of Excellence on Performance Optimisation and Productivity published the recording of a webinar on Asynchronous GPU Programming in OpenMP where Christian Terboven and Michael Klemm discuss the optimization of data transfers and asynchronous offloading, hybrid OpenMP and HIP, and advanced task synchronization. Watch now.</p><p>The post <a href=\"https://www.openmp.org/home-news/asynchronous-gpu-programming-in-openmp/\">Asynchronous GPU Programming in OpenMP</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2024/asynchronous-gpu-programming-in-openmp/",
            
            
            
            
            
            "date_published": "2024-06-03T21:14:21-06:00",
            "date_modified": "2024-06-03T21:14:21-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2024/the-openmp-arb-welcomes-new-member-cea/",
            "title": "The OpenMP ARB welcomes new member CEA",
            "summary": null,
            "content_text": "May 13, 2024 — CEA has joined the OpenMP® ARB, a group of leading hardware and software vendors and research organizations creating the standard for the most popular shared-memory parallel programming model in use today.The post The OpenMP ARB welcomes new member CEA appeared first on OpenMP.",
            "content_html": "<p>May 13, 2024 — CEA has joined the OpenMP® ARB, a group of leading hardware and software vendors and research organizations creating the standard for the most popular shared-memory parallel programming model in use today.</p><p>The post <a href=\"https://www.openmp.org/press-release/the-openmp-arb-welcomes-new-member-cea/\">The OpenMP ARB welcomes new member CEA</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2024/the-openmp-arb-welcomes-new-member-cea/",
            
            
            
            
            
            "date_published": "2024-05-13T08:00:03-06:00",
            "date_modified": "2024-05-13T08:00:03-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2024/iwomp-2024/",
            "title": "IWOMP 2024",
            "summary": null,
            "content_text": "Sept. 23, 2024  The 20th International Workshop on OpenMP - IWOMP is the premier forum to present and discuss issues, trends, recent research ideas, and results related to parallel programming with OpenMP.The post IWOMP 2024 appeared first on OpenMP.",
            "content_html": "<p>Sept. 23, 2024  The 20th International Workshop on OpenMP - IWOMP is the premier forum to present and discuss issues, trends, recent research ideas, and results related to parallel programming with OpenMP.</p><p>The post <a href=\"https://www.openmp.org/recent-events/iwomp-2024/\">IWOMP 2024</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2024/iwomp-2024/",
            
            
            
            
            
            "date_published": "2024-03-20T14:45:28-06:00",
            "date_modified": "2024-03-20T14:45:28-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/looking-forward-to-2024/",
            "title": "Looking forward to 2024!",
            "summary": null,
            "content_text": "      Looking forward to next year!This is my end-of-the year post as we all make our way into the New Year. We've done quite a lot of things this year to help make oneAPI easier to use - a lot of the blog posts I've written as been towards an eye to educate.We started off with some blog posts on how to use modern IDEs on Linux to write SYCL code and run them inside a container that we built, making a turn-key effort to build applications.There was the introduction to 'awesome oneAPI' which showed a set of curated links to oneAPI projects showcasing all the capabilities. We have been updating it regularly, so check it out! We are definitely looking for more AI related projects - are you thinking of a project for next year? Need help? Let me know!To complement the awesome oneAPI distribution, I have recently launched the oneAPI Web Showcase where we hope to discover upcoming projects that people are working on and showcasing them. There are also links on the website to help you start a project.We now have community-focused documentation!!I'll have another blog post up to show how you can help with the documentation by translating the documentation into different languages so that everybody can follow along in their native language. You can see the documentation at https://oneapi-community.github.io/documentation. We hope to grow it into a true community hub for oneAPI and SYCL. Exciting! All of these are community projects in themselves. Want to help out? Reach out or just submit a PR!      Goals for next yearI want to keep building on the work we've done in 2023. So many opportunities!! 2023 was all about meeting developers where they were. Now, it's also time to meet them where they are AND also communicate with them in their own language!!The key to  adopting open platforms is to:1) Have great documentation that's accessible in as many languages as possible.2) Plenty of code samples to look at how to do things.3) Great developer experience - be able to set up your environment and just go!4) Amazing community that interacts with each other, is active and works together.These are all totally possible!! But, oneAPI is relatively new and still under one vendor. With the formation of the UXL Foundation, we now have a neutral place for all vendors to congregate and work together. As a community, we should ask our hardware vendors to support level zero and be able to get all the advantages of hardware with a smooth hardware experience.So where do we want to go from here - here are my personal goals/wish list for next year!1) reproducible builds - we should be able to continuously build and test oneAPI software.2) More community assistance in documentation by helping translate the docs we have - as well as having more docs around tips and tricks.3) Adding more projects to Awesome oneAPI and having more PRs from the community to add their projects! :)      Have a wonderful holiday season and a Happy New Year!With that, I wish all of you a wonderful holiday season and looking forward to great things in the oneAPI ecosystem in 2024!!Photo by Jamie Street on Unsplash",
            "content_html": "<h2>      Looking forward to next year!</h2><p>This is my end-of-the year post as we all make our way into the New Year. </p><p>We've done quite a lot of things this year to help make oneAPI easier to use - a lot of the blog posts I've written as been towards an eye to educate.</p><p>We started off with some blog posts on how to use modern IDEs on Linux to write SYCL code and run them inside a container that we built, making a turn-key effort to build applications.</p><p>There was the introduction to '<a href=\"https://github.com/oneapi-community/awesome-oneapi\">awesome oneAPI</a>' which showed a set of curated links to oneAPI projects showcasing all the capabilities. We have been updating it regularly, so check it out! We are definitely looking for more AI related projects - are you thinking of a project for next year? Need help? Let me know!</p><p>To complement the awesome oneAPI distribution, I have recently launched the <a href=\"https://oneapi-community.github.io/\">oneAPI Web Showcase</a> where we hope to discover upcoming projects that people are working on and showcasing them. There are also links on the website to help you start a project.</p><p>We now have community-focused documentation!!</p><p>I'll have another blog post up to show how you can help with the documentation by translating the documentation into different languages so that everybody can follow along in their native language. You can see the documentation at <a href=\"https://oneapi-community.github.io/documentation\">https://oneapi-community.github.io/documentation</a>. We hope to grow it into a true community hub for oneAPI and SYCL. Exciting! All of these are community projects in themselves. Want to help out? Reach out or just submit a PR!</p><h2>      Goals for next year</h2><p>I want to keep building on the work we've done in 2023. So many opportunities!! 2023 was all about meeting developers where they were. Now, it's also time to meet them where they are AND also communicate with them in their own language!!</p><p>The key to  adopting open platforms is to:</p><p>1) Have great documentation that's accessible in as many languages as possible.<br />2) Plenty of code samples to look at how to do things.<br />3) Great developer experience - be able to set up your environment and just go!<br />4) Amazing community that interacts with each other, is active and works together.</p><p>These are all totally possible!! But, oneAPI is relatively new and still under one vendor. With the formation of the <a href=\"https://uxlfoundation.org/\">UXL Foundation</a>, we now have a neutral place for all vendors to congregate and work together. As a community, we should ask our hardware vendors to support level zero and be able to get all the advantages of hardware with a smooth hardware experience.</p><p>So where do we want to go from here - here are my personal goals/wish list for next year!</p><p>1) reproducible builds - we should be able to continuously build and test oneAPI software.<br />2) More community assistance in documentation by helping translate the docs we have - as well as having more docs around tips and tricks.<br />3) Adding more projects to Awesome oneAPI and having more PRs from the community to add their projects! :)</p><h2>      Have a wonderful holiday season and a Happy New Year!</h2><p>With that, I wish all of you a wonderful holiday season and looking forward to great things in the oneAPI ecosystem in 2024!!</p><p>Photo by <a href=\"https://unsplash.com/@jamie452?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Jamie Street</a> on <a href=\"https://unsplash.com/photos/multicolored-christmas-decors-yq68hBhi0RI?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Unsplash</a></p>",
            "url": "https://hpc.social/community-blog/2023/looking-forward-to-2024/",
            
            
            
            
            
            "date_published": "2023-12-22T06:16:33-07:00",
            "date_modified": "2023-12-22T06:16:33-07:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/building-oneapi-from-source/",
            "title": "Building oneAPI from Source",
            "summary": null,
            "content_text": "      Build oneAPI completely from gitI'm back!! A few raw posts have been languishing and I decided the end of the year was the perfect time to put them out there. This will be one of three (hopefully).I'm going to focus on how ￼to build oneAPI from git. This is somewhat of a return to my earlier blog post where I talked about how to build the DPC++ compiler and it included the binary versions of the openCL and level zero run time.That's all well and good but let's consider how we could build the run time from git completely. The ability to do reproducible builds is going to be important later when we dive into buildimg packaging that is up to date and available on any Linux distro.The build only supports Intel hardware at this point since level zero doesn't support NVidia or AMD GPUs. If you are looking for such support, you might consider Codeplay's plugins that will allow you to use NVidia and AMD hardware. These blog pages typically only focus on what we can do from an open source perspective and won't really focus on anything that has binary blobs if we can avoid it.DISCLAIMER: Please don't use this set up for a production environment. It is not well tested. If you find any problems, please reach out in the comments so that I can help debug and update the blog post appropriately.      Setting up the build environmentI like to use containers which makes it easy to quickly set up and automate using distrobox.You should be able to use whatever Linux distribution you want as long as you can install distrobox. You can, of course, use a virtual machine to accomplish this. I've used Vagrant successfully.Assuming that you have distrobox installed - let's get to it.Decide where you want to have the build for instance: ~/src/oneapi-build.$ distrobox create --image docker.io/library/ubuntu 20.04 --name \"oneAPIBuild\"$ distrobox enter oneAPIBuildYou should now be in a container running Ubuntu 20.04.      Install the appropriate packages$ sudo apt-get install -y build-essential git libssl-dev flex bison libz-dev python3-mako python3-pip automake autoconf libtool pkg-config rubyYou will need a recent version of cmake for the builds. The one that comes with 20.04 is too old.$  wget https://github.com/Kitware/CMake/releases/download/v3.28.1/cmake-3.28.1.tar.gz$ tar xvfpz cmake-3.28.1.tar.gz$ cd cmake-3.28.1$ ./boostrap$ ./configure$ make $ sudo make installNow you should have everything you need for the build.      Understanding the oneAPI BuildThere are a number of prerequisites before you start the build. Here is a graphic of how the oneAPI build is put together.The order of build is:1) Intel Graphics Engine and i￼ts relevant prerequisites which consist of:Intel Graphics Compiler (igc)SPIRV HeadersSPIRV Toolscopy of the llvm projectvc-intrinsicsintel graphcis compiler2) ocl-icd3) GMMLib4) NEO - Intel Compute Runtime - NEO is the primary GPU graphics driver and uses OpenCL to talk to the GPU.Has the following pre-requisites:Intel graphics compiler (IGC)GMMLib6) Level Zero7) DPC++ SYCL Compiler8) oneTBB LibraryThat's the progression to get the full build going.      Intel Graphics EngineLet's start building the first prerequisites for the NEO which is the Intel Graphics Engine:$ mkdir igc-workspace &amp;&amp; cd igc-workspace$ git clone https://github.com/KhronosGroup/SPIRV-Headers.git --depth 1$ git clone https://github.com/KhronosGroup/SPIRV-Tools.git --depth 1$ git clone -b llvmorg-14.0.5 https://github.com/llvm/llvm-project llvm-project --depth 1$ git clone -b ocl-open-140 https://github.com/intel/opencl-clang llvm-project/llvm/projects/opencl-clang --depth 1$ git clone -b llvm_release_140 https://github.com/KhronosGroup/SPIRV-LLVM-Translator llvm-project/llvm/projects/llvm-spirv --depth 1$ git clone https://github.com/intel/vc-intrinsics --depth 1$ git clone https://github.com/intel/intel-graphics-compiler igc --depth 1$ mkdir build &amp;&amp; cd build$ cmake ../igc -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make -j `nproc`$ sudo make installIt should build cleanly. If it doesn't - please check any errors and make sure you have all the prerequisites.      ocl-icdocl-icd is an OpenCL loader - and is used to link opencl software when compiling. Make sure you are back in your usual oneapi-build directory.$ pwd~/src/oneapi-build$ git clone https://github.com/OCL-dev/ocl-icd --depth 1$ cd ocl-icd$ ./bootstrap$ ./configure$ make$ sudo make install      Install GMMLibNEO requires GMMLib as one of its prerequisites so we will build that now.$ pwd~/src/oneapi-build$ git clone https://github.com/intel/gmmlib --depth 1$ cd gmmlib$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ sudo make install      Install NEONEO is the Intel Compute Runtime and is necessary for the SYCL based applications to talk to the GPU. Go back to your ~/src/oneapi-build directory.$ pwd ~/src/oneapi-build # please note this output will be different for you$ mkdir neo-workspace$ cd neo-workspace$ git clone https://github.com/intel/compute-runtime neo –depth 1$ cd neo$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ sudo make install      Install level-zeroThis is the main part of oneAPI and interfaces with NEO or other run times. Since NEO is the only one at the moment - it will only work with Intel devices.$ pwd~/src/oneapi-build$ git clone https://github.com/oneapi-src/level-zero --depth 1$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ sudo make install      Install the DPC++ CompilerNow to build the SYCL Compiler.$ pwd~/src/oneapi-build$ mkdir sycl_workspace &amp;&amp; cd sycl_workspace$ export DPCPP_HOME=`pwd`$ git clone https://github.com/intel/llvm.git -b sycl --depth 1$ python3 $DPCPP_HOME/llvm/buildbot/configure.py --cmake-opt CMAKE_BUILD_PREFIX=\"/usr/local\"$ python3 $DPCPP_HOME/llvm/buildbot/compile.py      Install oneTBBFinally, we need to install oneTBB$ pwd~/src/oneapi-build$ git clone https://github.com/oneapi-src/oneTBB --depth 1$ cd oneTBB$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ make install      Set the LD_LIBRARY_PATHWe need to make sure that the linker can find the proper libraries. The easiest way is to either set the LD_LIBRARY_PATH in your .bashrc or put it in /etc/environment.$ export LD_LIBRARY_PATH=\"/usr/local/lib\"      Test the environment$ cd ~/src$ mkdir simple-oneapi-app$ cd simple-oneapi-app$ cat &gt; simple-oneapi-app.cpp#include &lt;sycl/sycl.hpp&gt;int main() {  // Creating buffer of 4 ints to be used inside the kernel code  sycl::buffer&lt;sycl::cl_int, 1&gt; Buffer(4);  // Creating SYCL queue  sycl::queue Queue;  // Size of index space for kernel  sycl::range&lt;1&gt; NumOfWorkItems{Buffer.size()};  // Submitting command group(work) to queue  Queue.submit([&amp;](sycl::handler &amp;cgh) {    // Getting write only access to the buffer on a device    auto Accessor = Buffer.get_access&lt;sycl::access::mode::write&gt;(cgh);    // Executing kernel    cgh.parallel_for&lt;class FillBuffer&gt;(        NumOfWorkItems, [=](sycl::id&lt;1&gt; WIid) {          // Fill buffer with indexes          Accessor[WIid] = (sycl::cl_int)WIid.get(0);        });  });  // Getting read only access to the buffer on the host.  // Implicit barrier waiting for queue to complete the work.  const auto HostAccessor = Buffer.get_access&lt;sycl::access::mode::read&gt;();  // Check the results  bool MismatchFound = false;  for (size_t I = 0; I &lt; Buffer.size(); ++I) {    if (HostAccessor[I] != I) {      std::cout &lt;&lt; \"The result is incorrect for element: \" &lt;&lt; I                &lt;&lt; \" , expected: \" &lt;&lt; I &lt;&lt; \" , got: \" &lt;&lt; HostAccessor[I]                &lt;&lt; std::endl;      MismatchFound = true;    }  }  if (!MismatchFound) {    std::cout &lt;&lt; \"The results are correct!\" &lt;&lt; std::endl;  }  return MismatchFound;}$ clang++ -fsycl simple-oneapi-app.cpp -o simple-oneapi-appWhen you run the app you should get \"Results are correct!\".$ ./simple-oneapi-appResults are correct!Now you've successfully built oneAPI from source!Let me know if you have any issues with the instructions in the comments.Photo by Dominik Lückmann on Unsplash",
            "content_html": "<h2>      Build oneAPI completely from git</h2><p>I'm back!! A few raw posts have been languishing and I decided the end of the year was the perfect time to put them out there. This will be one of three (hopefully).</p><p>I'm going to focus on how ￼to build oneAPI from git. This is somewhat of a return to my earlier blog post where I talked about how to build the DPC++ compiler and it included the binary versions of the openCL and level zero run time.</p><p>That's all well and good but let's consider how we could build the run time from git completely. The ability to do reproducible builds is going to be important later when we dive into buildimg packaging that is up to date and available on any Linux distro.</p><p>The build only supports Intel hardware at this point since level zero doesn't support NVidia or AMD GPUs. If you are looking for such support, you might consider Codeplay's plugins that will allow you to use NVidia and AMD hardware. </p><p>These blog pages typically only focus on what we can do from an open source perspective and won't really focus on anything that has binary blobs if we can avoid it.</p><p>DISCLAIMER: Please don't use this set up for a production environment. It is not well tested. If you find any problems, please reach out in the comments so that I can help debug and update the blog post appropriately.</p><h2>      Setting up the build environment</h2><p>I like to use containers which makes it easy to quickly set up and automate using distrobox.</p><p>You should be able to use whatever Linux distribution you want as long as you can install distrobox. You can, of course, use a virtual machine to accomplish this. I've used Vagrant successfully.</p><p>Assuming that you have distrobox installed - let's get to it.</p><p>Decide where you want to have the build for instance: ~/src/oneapi-build.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ distrobox create --image docker.io/library/ubuntu 20.04 --name \"oneAPIBuild\"$ distrobox enter oneAPIBuild</code></pre></div><p>You should now be in a container running Ubuntu 20.04.</p><h3>      Install the appropriate packages</h3><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ sudo apt-get install -y build-essential git libssl-dev flex bison libz-dev python3-mako python3-pip automake autoconf libtool pkg-config ruby</code></pre></div><p>You will need a recent version of cmake for the builds. The one that comes with 20.04 is too old.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$  wget https://github.com/Kitware/CMake/releases/download/v3.28.1/cmake-3.28.1.tar.gz$ tar xvfpz cmake-3.28.1.tar.gz$ cd cmake-3.28.1$ ./boostrap$ ./configure$ make $ sudo make install</code></pre></div><p>Now you should have everything you need for the build.</p><h3>      Understanding the oneAPI Build</h3><p>There are a number of prerequisites before you start the build. Here is a graphic of how the oneAPI build is put together.</p><p>The order of build is:</p><p>1) Intel Graphics Engine and i￼ts relevant prerequisites which consist of:</p><ul><li>Intel Graphics Compiler (igc)<ol><li>SPIRV Headers</li><li>SPIRV Tools</li><li>copy of the llvm project</li><li>vc-intrinsics</li><li>intel graphcis compiler2) ocl-icd3) GMMLib4) NEO - Intel Compute Runtime - NEO is the primary GPU graphics driver and uses OpenCL to talk to the GPU.</li></ol></li><li>Has the following pre-requisites:<ol><li>Intel graphics compiler (IGC)</li><li>GMMLib6) Level Zero7) DPC++ SYCL Compiler8) oneTBB Library</li></ol></li></ul><p>That's the progression to get the full build going.</p><h3>      Intel Graphics Engine</h3><p>Let's start building the first prerequisites for the NEO which is the Intel Graphics Engine:<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ mkdir igc-workspace &amp;&amp; cd igc-workspace$ git clone https://github.com/KhronosGroup/SPIRV-Headers.git --depth 1$ git clone https://github.com/KhronosGroup/SPIRV-Tools.git --depth 1$ git clone -b llvmorg-14.0.5 https://github.com/llvm/llvm-project llvm-project --depth 1$ git clone -b ocl-open-140 https://github.com/intel/opencl-clang llvm-project/llvm/projects/opencl-clang --depth 1$ git clone -b llvm_release_140 https://github.com/KhronosGroup/SPIRV-LLVM-Translator llvm-project/llvm/projects/llvm-spirv --depth 1$ git clone https://github.com/intel/vc-intrinsics --depth 1$ git clone https://github.com/intel/intel-graphics-compiler igc --depth 1$ mkdir build &amp;&amp; cd build$ cmake ../igc -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make -j `nproc`$ sudo make install</code></pre></div><p>It should build cleanly. If it doesn't - please check any errors and make sure you have all the prerequisites.</p><h3>      ocl-icd</h3><p>ocl-icd is an OpenCL loader - and is used to link opencl software when compiling. Make sure you are back in your usual oneapi-build directory.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ pwd~/src/oneapi-build$ git clone https://github.com/OCL-dev/ocl-icd --depth 1$ cd ocl-icd$ ./bootstrap$ ./configure$ make$ sudo make install</code></pre></div><h3>      Install GMMLib</h3><p>NEO requires GMMLib as one of its prerequisites so we will build that now.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ pwd~/src/oneapi-build$ git clone https://github.com/intel/gmmlib --depth 1$ cd gmmlib$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ sudo make install</code></pre></div><h3>      Install NEO</h3><p>NEO is the Intel Compute Runtime and is necessary for the SYCL based applications to talk to the GPU. Go back to your ~/src/oneapi-build directory.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ pwd ~/src/oneapi-build # please note this output will be different for you$ mkdir neo-workspace$ cd neo-workspace$ git clone https://github.com/intel/compute-runtime neo –depth 1$ cd neo$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ sudo make install</code></pre></div><h2>      Install level-zero</h2><p>This is the main part of oneAPI and interfaces with NEO or other run times. Since NEO is the only one at the moment - it will only work with Intel devices.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ pwd~/src/oneapi-build$ git clone https://github.com/oneapi-src/level-zero --depth 1$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ sudo make install</code></pre></div><h2>      Install the DPC++ Compiler</h2><p>Now to build the SYCL Compiler.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ pwd~/src/oneapi-build$ mkdir sycl_workspace &amp;&amp; cd sycl_workspace$ export DPCPP_HOME=`pwd`$ git clone https://github.com/intel/llvm.git -b sycl --depth 1$ python3 $DPCPP_HOME/llvm/buildbot/configure.py --cmake-opt CMAKE_BUILD_PREFIX=\"/usr/local\"$ python3 $DPCPP_HOME/llvm/buildbot/compile.py</code></pre></div><h2>      Install oneTBB</h2><p>Finally, we need to install oneTBB<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ pwd~/src/oneapi-build$ git clone https://github.com/oneapi-src/oneTBB --depth 1$ cd oneTBB$ mkdir build$ cd build$ cmake .. -DCMAKE_INSTALL_PREFIX=\"/usr/local\"$ make$ make install</code></pre></div><h2>      Set the LD_LIBRARY_PATH</h2><p>We need to make sure that the linker can find the proper libraries. The easiest way is to either set the LD_LIBRARY_PATH in your .bashrc or put it in /etc/environment.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ export LD_LIBRARY_PATH=\"/usr/local/lib\"</code></pre></div><h2>      Test the environment</h2><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ cd ~/src$ mkdir simple-oneapi-app$ cd simple-oneapi-app$ cat &gt; simple-oneapi-app.cpp#include &lt;sycl/sycl.hpp&gt;int main() {  // Creating buffer of 4 ints to be used inside the kernel code  sycl::buffer&lt;sycl::cl_int, 1&gt; Buffer(4);  // Creating SYCL queue  sycl::queue Queue;  // Size of index space for kernel  sycl::range&lt;1&gt; NumOfWorkItems{Buffer.size()};  // Submitting command group(work) to queue  Queue.submit([&amp;](sycl::handler &amp;cgh) {    // Getting write only access to the buffer on a device    auto Accessor = Buffer.get_access&lt;sycl::access::mode::write&gt;(cgh);    // Executing kernel    cgh.parallel_for&lt;class FillBuffer&gt;(        NumOfWorkItems, [=](sycl::id&lt;1&gt; WIid) {          // Fill buffer with indexes          Accessor[WIid] = (sycl::cl_int)WIid.get(0);        });  });  // Getting read only access to the buffer on the host.  // Implicit barrier waiting for queue to complete the work.  const auto HostAccessor = Buffer.get_access&lt;sycl::access::mode::read&gt;();  // Check the results  bool MismatchFound = false;  for (size_t I = 0; I &lt; Buffer.size(); ++I) {    if (HostAccessor[I] != I) {      std::cout &lt;&lt; \"The result is incorrect for element: \" &lt;&lt; I                &lt;&lt; \" , expected: \" &lt;&lt; I &lt;&lt; \" , got: \" &lt;&lt; HostAccessor[I]                &lt;&lt; std::endl;      MismatchFound = true;    }  }  if (!MismatchFound) {    std::cout &lt;&lt; \"The results are correct!\" &lt;&lt; std::endl;  }  return MismatchFound;}$ clang++ -fsycl simple-oneapi-app.cpp -o simple-oneapi-app</code></pre></div><p>When you run the app you should get \"Results are correct!\".<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>$ ./simple-oneapi-appResults are correct!</code></pre></div><p>Now you've successfully built oneAPI from source!</p><p>Let me know if you have any issues with the instructions in the comments.</p><p>Photo by <a href=\"https://unsplash.com/@exdigy?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Dominik Lückmann</a> on <a href=\"https://unsplash.com/photos/blue-and-red-cargo-ship-4aOhA4ptIY4?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash\">Unsplash</a></p>",
            "url": "https://hpc.social/community-blog/2023/building-oneapi-from-source/",
            
            
            
            
            
            "date_published": "2023-12-22T06:08:31-07:00",
            "date_modified": "2023-12-22T06:08:31-07:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/supercomputing-2023-hpc-social-summary/",
            "title": "Supercomputing 2023 - HPC Social Summary!",
            "summary": null,
            "content_text": "What a week! We participated in person and virtually for Supercomputing 2023 in Denver. While we cannot cover all the exciting happenings, we will review a brief set of events of interest here.HPC Social Virtual Noodles AwardThis year we launched the first HPC Social Noodles Award, a celebration of our frustrations and comical takes on the events of the year. THe top noodle was, of course, the whole CentOS debacle, followed by a few gripes about software and vendors, and the funny noodles starting at item 7 and on.Beowulf BashHPC Social was present (and giving out stickers) at the bash this year! The branding was… excellent.I Want to Run my MPIThis was a parody music video made by community leader @vsoch to celebrate a generic HPC technology (MPI) in the high performance community!She made an effort to engage others to participate, and was only moderately successful to get a few shared pictures. It would be a fun idea if others wanted to participate to a greater extent at some future Supercomputing!Official GreetingThe “official” greeting for SC23 was tapping someone on the shoulder, as announced by HPC Guru.Texas Tech Tiny Cluster!Our very own Alan Sill hosted a booth to show up a tiny cluster! While Raspberry Pi clusters have been around for a long time and useful in hobbyist activities, training, home automation, and training, this was one of the first such small clusters running Fedora 39 as a natively installed OS on the head node and Enterprise Linux (in this case Rocky) on the worker nodes. More to come as other mainline popular cluster tools like Warewulf, Spack and/or EasyBuild, and Slurm and/or Flux schedulars are added.The HPC Social CommunityAnd finally, we close with a few shots shared in the HPC Social slack! We love our community! ❤️Felix (finally) got his “I am HPC Guru” pin!",
            "content_html": "<p>What a week! We participated in person and virtually for <a href=\"https://sc23.supercomputing.org/\">Supercomputing 2023</a> in Denver. While we cannot cover all the exciting happenings, we will review a brief set of events of interest here.</p><h2 id=\"hpc-social-virtual-noodles-award\">HPC Social Virtual Noodles Award</h2><p>This year we launched the first <a href=\"https://hpc.social/noodles-award/\">HPC Social Noodles Award</a>, a celebration of our frustrations and comical takes on the events of the year. THe top noodle was, of course, the whole CentOS debacle, followed by a few gripes about software and vendors, and the funny noodles starting at item 7 and on.</p><h2 id=\"beowulf-bash\">Beowulf Bash</h2><p>HPC Social was present (and giving out stickers) at the <a href=\"https://beowulfbash.com/\">bash</a> this year! The branding was… excellent.</p><p><img alt=\"/assets/img/posts/sc23/bash.png\" src=\"https://hpc-social.github.io/assets/img/posts/sc23/bash.png\" /></p><h2 id=\"i-want-to-run-my-mpi\">I Want to Run my MPI</h2><p>This was a parody music video made by community leader <a href=\"https://github.com/vsoch\">@vsoch</a> to celebrate a generic HPC technology (MPI) in the high performance community!</p><p>She made an effort to engage others to participate, and was only moderately successful to get a few shared pictures. It would be a fun idea if others wanted to participate to a greater extent at some future Supercomputing!</p><h2 id=\"official-greeting\">Official Greeting</h2><p>The “official” greeting for SC23 was tapping someone on the shoulder, as <a href=\"https://twitter.com/HPC_Guru/status/1723539957124604325\">announced by HPC Guru</a>.</p><p><img alt=\"/assets/img/posts/sc23/shoulder-tap.jpeg\" src=\"https://hpc-social.github.io/assets/img/posts/sc23/shoulder-tap.jpeg\" /></p><h2 id=\"texas-tech-tiny-cluster\">Texas Tech Tiny Cluster!</h2><p>Our very own Alan Sill hosted a booth to show up a tiny cluster! While Raspberry Pi clusters have been around for a long time and useful in hobbyist activities, training, home automation, and training, this was one of the first such small clusters running Fedora 39 as a natively installed OS on the head node and Enterprise Linux (in this case Rocky) on the worker nodes. More to come as other mainline popular cluster tools like Warewulf, Spack and/or EasyBuild, and Slurm and/or Flux schedulars are added.</p><p><img alt=\"/assets/img/posts/sc23/tiny-cluster-1.jpg\" src=\"https://hpc-social.github.io/assets/img/posts/sc23/tiny-cluster-1.jpg\" /><img alt=\"/assets/img/posts/sc23/tiny-cluster-2.jpg\" src=\"https://hpc-social.github.io/assets/img/posts/sc23/tiny-cluster-2.jpg\" /></p><h2 id=\"the-hpc-social-community\">The HPC Social Community</h2><p>And finally, we close with a few shots shared in the HPC Social slack! We love our community! ❤️</p><p><img alt=\"/assets/img/posts/sc23/jarett-share.jpg\" src=\"https://hpc-social.github.io/assets/img/posts/sc23/jarett-share.jpg\" /></p><p>Felix (finally) got his “I am HPC Guru” pin!</p><p><img alt=\"/assets/img/posts/sc23/felix.jpeg\" src=\"https://hpc-social.github.io/assets/img/posts/sc23/felix.jpeg\" /></p>",
            "url": "https://hpc.social/community-blog/2023/supercomputing-2023-hpc-social-summary/",
            
            
            
            
            
            "date_published": "2023-11-17T00:00:00-07:00",
            "date_modified": "2023-11-17T00:00:00-07:00",
            
                "author": "hpc.social"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/supercomputing-2023/",
            "title": "Supercomputing 2023",
            "summary": null,
            "content_text": "November 12, 2023OpenMP will be in Denver for Supercomputing 2023 with four tutorials, a BOF, and more.The post Supercomputing 2023 appeared first on OpenMP.",
            "content_html": "<p>November 12, 2023<br />OpenMP will be in Denver for Supercomputing 2023 with four tutorials, a BOF, and more.</p><p>The post <a href=\"https://www.openmp.org/events/sc23/\">Supercomputing 2023</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/supercomputing-2023/",
            
            
            
            
            
            "date_published": "2023-11-12T18:22:52-07:00",
            "date_modified": "2023-11-12T18:22:52-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/openmp-arb-releases-technical-report-12/",
            "title": "OpenMP ARB Releases Technical Report 12",
            "summary": null,
            "content_text": "The OpenMP® Architecture Review Board (ARB) has released Technical Report 12, the second preview of version 6.0 of the OpenMP API, which will be released in 2024.The post OpenMP ARB Releases Technical Report 12 appeared first on OpenMP.",
            "content_html": "<p>The OpenMP® Architecture Review Board (ARB) has released Technical Report 12, the second preview of version 6.0 of the OpenMP API, which will be released in 2024.</p><p>The post <a href=\"https://www.openmp.org/press-release/openmp-arb-releases-technical-report-12/\">OpenMP ARB Releases Technical Report 12</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/openmp-arb-releases-technical-report-12/",
            
            
            
            
            
            "date_published": "2023-11-09T07:30:51-07:00",
            "date_modified": "2023-11-09T07:30:51-07:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/fortran-package-manager-and-openmp/",
            "title": "Fortran Package Manager and OpenMP",
            "summary": null,
            "content_text": "The Fortran Package Manager, or fpm, is a community-driven, open-source build tool and package manager for the Fortran language. fpm makes it easy for beginners to develop applications. It streamlines project setup by quickly and easily generating Fortran project templates, facilitating rapid prototyping.The post Fortran Package Manager and OpenMP appeared first on OpenMP.",
            "content_html": "<p>The Fortran Package Manager, or fpm, is a community-driven, open-source build tool and package manager for the Fortran language. fpm makes it easy for beginners to develop applications. It streamlines project setup by quickly and easily generating Fortran project templates, facilitating rapid prototyping.</p><p>The post <a href=\"https://www.openmp.org/blog/fortran-package-manager-and-openmp/\" rel=\"nofollow\">Fortran Package Manager and OpenMP</a> appeared first on <a href=\"https://www.openmp.org\" rel=\"nofollow\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/fortran-package-manager-and-openmp/",
            
            
            
            
            
            "date_published": "2023-10-11T17:35:25-06:00",
            "date_modified": "2023-10-11T17:35:25-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/oneapi-moves-to-unified-acceleration-foundation-uxl/",
            "title": "oneAPI moves to Unified Acceleration Foundation (UXL)",
            "summary": null,
            "content_text": "As accelerators have become more prevalent in the industry there has been a bifurcation in the industry which typically resolves itself. Initially there has been many efforts by a myriad of vendors in the GPU accelerator space with various degrees of openness.For a long period of time, incubation of the oneAPI ecosystem started at Intel through both DPC++ SYCL compiler, and the publishing of open specifications of oneAPI and their open source implementations. While the messaging around the specs were that they were open to all contributors – it could be hard to feel comfortable especially for competitors to enter spaces where the perception is that it isn’t a true neutral space. With oneAPI spec’s now under the aegis of the Linux Foundation the spec and the open source implementations will be well managed under established norms. There is now a true center of gravity to work together as equal partners on the oneAPI spec and their open source implementations.We can now focus on driving a true industry driven standard on heterogeneous computing under the UXL Foundation and have some serious collaboration to finally use all your hardware. This will herald a sustainable ecosystem that we can all be proud of.There are still challenges going forward. How our toolchains work together under UXL Foundation is going to be important going forward. We can address these concerns by vigorously participating in the UXL Foundation. Creating an open ecosystem is always challenging as many many partners need to agree and align on goals and processes. Listening to each other and the community is going to be key going forward.With all that being said - I hope that you will take the time to look at what has been established so far. We have a humble beginning but with your help and participation we can take it to the next level. For further reading, please see https://uxlfoundation.org/. Looking forward to seeing you all there.Cover image: Photo by Scott Blake on Unsplash",
            "content_html": "<p>As accelerators have become more prevalent in the industry there has been a bifurcation in the industry which typically resolves itself. Initially there has been many efforts by a myriad of vendors in the GPU accelerator space with various degrees of openness.</p><p>For a long period of time, incubation of the oneAPI ecosystem started at Intel through both DPC++ SYCL compiler, and the publishing of open specifications of oneAPI and their open source implementations. While the messaging around the specs were that they were open to all contributors – it could be hard to feel comfortable especially for competitors to enter spaces where the perception is that it isn’t a true neutral space. </p><p>With oneAPI spec’s now under the aegis of the Linux Foundation the spec and the open source implementations will be well managed under established norms. There is now a true center of gravity to work together as equal partners on the oneAPI spec and their open source implementations.</p><p>We can now focus on driving a true industry driven standard on heterogeneous computing under the UXL Foundation and have some serious collaboration to finally use all your hardware. This will herald a sustainable ecosystem that we can all be proud of.</p><p>There are still challenges going forward. How our toolchains work together under UXL Foundation is going to be important going forward. We can address these concerns by vigorously participating in the UXL Foundation. Creating an open ecosystem is always challenging as many many partners need to agree and align on goals and processes. Listening to each other and the community is going to be key going forward.</p><p>With all that being said - I hope that you will take the time to look at what has been established so far. We have a humble beginning but with your help and participation we can take it to the next level. For further reading, please see <a href=\"https://uxlfoundation.org/\">https://uxlfoundation.org/</a>. Looking forward to seeing you all there.</p><p>Cover image: Photo by <a href=\"https://unsplash.com/@sunburned_surveyor?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Scott Blake</a> on <a href=\"https://unsplash.com/photos/DodJfxuH46I?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></p>",
            "url": "https://hpc.social/community-blog/2023/oneapi-moves-to-unified-acceleration-foundation-uxl/",
            
            
            
            
            
            "date_published": "2023-09-30T03:36:38-06:00",
            "date_modified": "2023-09-30T03:36:38-06:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/iwomp-2023/",
            "title": "IWOMP 2023",
            "summary": null,
            "content_text": "Sept. 12, 2023  The 19th International Workshop on OpenMP - IWOMP is the premier forum to present and discuss issues, trends, recent research ideas, and results related to parallel programming with OpenMP.The post IWOMP 2023 appeared first on OpenMP.",
            "content_html": "<p>Sept. 12, 2023  The 19th International Workshop on OpenMP - IWOMP is the premier forum to present and discuss issues, trends, recent research ideas, and results related to parallel programming with OpenMP.</p><p>The post <a href=\"https://www.openmp.org/recent-events/iwomp-2021-2/\">IWOMP 2023</a> appeared first on <a href=\"https://www.openmp.org\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/iwomp-2023/",
            
            
            
            
            
            "date_published": "2023-09-12T21:35:36-06:00",
            "date_modified": "2023-09-12T21:35:36-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/migrating-reduction-operations-to-sycl-in-a-molecular-docking-application/",
            "title": "Migrating reduction operations to SYCL in a molecular docking application",
            "summary": null,
            "content_text": "I completed porting of a molecular docking application from CUDA to SYCL using the Intel® DPC++ Compatibility Tool (Compatibility Tool) in June 2021. Let me share selected techniques that I used without delving into the details of the docking application. If you want to learn how to use this tool to migrate CUDA applications to SYCL, please refer to [1].The Compatibility Tool adds comments in the code where manual migration may be required. Typically, the manual changes required fall into two categories. First, changes are required for the code to compile and make the code functionally correct. Other changes are necessary to get better performance. Here, I will cover code that uses the operation of 'reduction'. Reductions are frequently used in High Performance Computing and scientific applications and can be performance hotspots. The first example finds the sum of integers and the second finds the minimum of floats and the identifier of the run that corresponds to the minimum.      Integer Reductions to find the number of evaluationsThe  docking application performs integer reductions to keep a running count of the number of score evaluations. This reduction is  implemented as a multi-line macro in CUDA as shown below.#define REDUCEINTEGERSUM(value, pAccumulator)         if (threadIdx.x == 0)         {             *pAccumulator = 0;         }         __threadfence();         __syncthreads();         if (__any_sync(0xffffffff, value != 0))         {             uint32_t tgx            = threadIdx.x &amp; cData.warpmask;             value                  += __shfl_sync(0xffffffff, value, tgx ^ 1);             value                  += __shfl_sync(0xffffffff, value, tgx ^ 2);             value                  += __shfl_sync(0xffffffff, value, tgx ^ 4);             value                  += __shfl_sync(0xffffffff, value, tgx ^ 8);             value                  += __shfl_sync(0xffffffff, value, tgx ^ 16);             if (tgx == 0)             {                 atomicAdd(pAccumulator, value);             }         }         __threadfence();         __syncthreads();         value = *pAccumulator;         __syncthreads();Let us review what this code is doing:The code is called for each work item (thread) in a work group (warp)*pAccumulator is where the final sum is stored summing across all work itemsThe combination of __threadfence() and __syncthreads() guarantees memory consistency and synchronizes threads in the warp at the point of the call.The __any_sync() call executes the block for those non-exited threads for which 'value != 0'The following __shfl_sync calls do a tree-wise summing with the final sum available in the first thread in the warp in variable valueThe value is then added to the Accumulator atomically with atomicAdd and finally all threads assign the sum to the value variable.For more details about these CUDA calls please refer to [2].The Compatibility tool was not able to automatically migrate this code with the following comments./*DPCT1023:40: The DPC++ sub-group does not support mask options for sycl::ext::oneapi::any_of.DPCT1023:41: The DPC++ sub-group does not support mask options for shuffle.DPCT1007:39: Migration of this CUDA API is not supported by the Intel(R) DPC++ Compatibility Tool.*/However, SYCL supports a rich set of functions for performing reductions. In this case, the reduce_over_group() function in SYCL can be used to create the same functionality as the above code as follows.#define REDUCEINTEGERSUM(value, pAccumulator)             int val = sycl::reduce_over_group(item_ct1.get_group(), value, std::plus&lt;&gt;());              *pAccumulator = val;             item_ct1.barrier(sycl::access::fence_space::local_space);The sycl::reduce_over_group is a collective function. The usage of this function simplifies the macro. The function takes the group, the value to be reduced, and the reduction operation which in this case is plus or summation. The function can adapt to varied sizes of work groups in SYCL and will use the best available optimizations available per the compiler and run-time.      Finding the minimum energyIn another part of the application, a block of CUDA threads perform shuffles to find the minimum of scores v0 and the corresponding identifier k0 of the run in the simulation that is the minimum score. The CUDA code calls a macro WARPMINIMUM2 (not shown) which in turn calls another macro WARPMINIMUMEXCHANGE (shown) with mask set to 1, 2, 4, 8, and 16.#define WARPMINIMUMEXCHANGE(tgx, v0, k0, mask)         {             float v1    = v0;             int k1      = k0;             int otgx    = tgx ^ mask;             float v2    = __shfl_sync(0xffffffff, v0, otgx);             int k2      = __shfl_sync(0xffffffff, k0, otgx);             int flag    = ((v1 &lt; v2) ^ (tgx &gt; otgx)) &amp;&amp; (v1 != v2);             k0          = flag ? k1 : k2;             v0          = flag ? v1 : v2;         }The __shfl_sync provides a way of moving a value from one thread to other threads in the warp in one instruction. In this code snippet __shfl_sync gets the v0 or k0 value from the thread identified by the otgx mask and saves it in v2, k2 variables. We then compare v1 with v2 to set flag and eventually store the minimum in v0 and the run identifier for this minimum in k0.Compatibility Tool could not completely migrate this code and included this comment as the reason it could not. However, Compatibility Tool correctly replaced the __shfl_sync call with SYCL shuffle call as shown in the below diff which shows the manual change./*DPCT1023:57: The DPC++ sub-group does not support mask options for shuffle.*/This comment indicates that the shuffle call in SYCL does not use a mask as shown below.#define WARPMINIMUMEXCHANGE(tgx, v0, k0, mask)             {                     float v1 = v0;                     int k1 = k0;                     int otgx = tgx ^ mask;     -               float v2 = item_ct1.get_sub_group().shuffle(energy, otgx);     +               float v2 = item_ct1.get_sub_group().shuffle(v0, otgx);  -               int k2 = item_ct1.get_sub_group().shuffle(bestID, otgx);     +               int k2 = item_ct1.get_sub_group().shuffle(k0, otgx);                     int flag = ((v1 &lt; v2) ^ (tgx &gt; otgx)) &amp;&amp; (v1 != v2);                     k0 = flag ? k1 : k2;                     v0 = flag ? v1 : v2;             }In this case, Compatibility Tool performed incorrect variable substitution for v0 and k0 in the shuffle calls using energy and bestID variables from the caller function. We manually fixed this by replacing energy with v0 and bestID with k0. This bug has been fixed in recent versions of the Compatibility Tool.      SummaryIn summary, reduction operations in CUDA applications may not be migrated correctly by the Compatibility Tool. Review the comments provided by the tool to understand if manual migration is necessary and what change might be required. A good understanding of the original CUDA code will then help to make manual changes to develop functionally correct code in SYCL.[1] https://www.intel.com/content/www/us/en/docs/dpcpp-compatibility-tool/get-started-guide/2023-1/overview.html[2] https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/",
            "content_html": "<p>I completed porting of a molecular docking application from CUDA to SYCL using the Intel® DPC++ Compatibility Tool (Compatibility Tool) in June 2021. Let me share selected techniques that I used without delving into the details of the docking application. If you want to learn how to use this tool to migrate CUDA applications to SYCL, please refer to [1].</p><p>The Compatibility Tool adds comments in the code where manual migration may be required. Typically, the manual changes required fall into two categories. First, changes are required for the code to compile and make the code functionally correct. Other changes are necessary to get better performance. Here, I will cover code that uses the operation of 'reduction'. Reductions are frequently used in High Performance Computing and scientific applications and can be performance hotspots. The first example finds the sum of integers and the second finds the minimum of floats and the identifier of the run that corresponds to the minimum.</p><h2>      Integer Reductions to find the number of evaluations</h2><p>The  docking application performs integer reductions to keep a running count of the number of score evaluations. This reduction is  implemented as a multi-line macro in CUDA as shown below.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight cuda\"><code><span class=\"cp\">#define REDUCEINTEGERSUM(value, pAccumulator)     </span>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>         <span class=\"p\">{</span>             <span class=\"o\">*</span><span class=\"n\">pAccumulator</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>         <span class=\"p\">}</span>         <span class=\"n\">__threadfence</span><span class=\"p\">();</span>         <span class=\"n\">__syncthreads</span><span class=\"p\">();</span>         <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">__any_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">value</span> <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">))</span>         <span class=\"p\">{</span>             <span class=\"kt\">uint32_t</span> <span class=\"n\">tgx</span>            <span class=\"o\">=</span> <span class=\"n\">threadIdx</span><span class=\"p\">.</span><span class=\"n\">x</span> <span class=\"o\">&amp;</span> <span class=\"n\">cData</span><span class=\"p\">.</span><span class=\"n\">warpmask</span><span class=\"p\">;</span>             <span class=\"n\">value</span>                  <span class=\"o\">+=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">tgx</span> <span class=\"o\">^</span> <span class=\"mi\">1</span><span class=\"p\">);</span>             <span class=\"n\">value</span>                  <span class=\"o\">+=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">tgx</span> <span class=\"o\">^</span> <span class=\"mi\">2</span><span class=\"p\">);</span>             <span class=\"n\">value</span>                  <span class=\"o\">+=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">tgx</span> <span class=\"o\">^</span> <span class=\"mi\">4</span><span class=\"p\">);</span>             <span class=\"n\">value</span>                  <span class=\"o\">+=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">tgx</span> <span class=\"o\">^</span> <span class=\"mi\">8</span><span class=\"p\">);</span>             <span class=\"n\">value</span>                  <span class=\"o\">+=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">,</span> <span class=\"n\">tgx</span> <span class=\"o\">^</span> <span class=\"mi\">16</span><span class=\"p\">);</span>             <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">tgx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">)</span>             <span class=\"p\">{</span>                 <span class=\"n\">atomicAdd</span><span class=\"p\">(</span><span class=\"n\">pAccumulator</span><span class=\"p\">,</span> <span class=\"n\">value</span><span class=\"p\">);</span>             <span class=\"p\">}</span>         <span class=\"p\">}</span>         <span class=\"n\">__threadfence</span><span class=\"p\">();</span>         <span class=\"n\">__syncthreads</span><span class=\"p\">();</span>         <span class=\"n\">value</span> <span class=\"o\">=</span> <span class=\"o\">*</span><span class=\"n\">pAccumulator</span><span class=\"p\">;</span>         <span class=\"n\">__syncthreads</span><span class=\"p\">();</span></code></pre></div><p>Let us review what this code is doing:</p><ul><li>The code is called for each work item (thread) in a work group (warp)</li><li><em>*pAccumulator</em> is where the final sum is stored summing across all work items</li><li>The combination of <em>__threadfence()</em> and <em>__syncthreads()</em> guarantees memory consistency and synchronizes threads in the warp at the point of the call.</li><li>The <em>__any_sync()</em> call executes the block for those non-exited threads for which <em>'value != 0'</em></li><li>The following <em>__shfl_sync</em> calls do a tree-wise summing with the final sum available in the first thread in the warp in variable <em>value</em></li><li>The <em>value</em> is then added to the Accumulator atomically with <em>atomicAdd</em> and finally all threads assign the sum to the <em>value</em> variable.</li></ul><p>For more details about these CUDA calls please refer to [2].</p><p>The Compatibility tool was not able to automatically migrate this code with the following comments.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>/*DPCT1023:40: The DPC++ sub-group does not support mask options for sycl::ext::oneapi::any_of.DPCT1023:41: The DPC++ sub-group does not support mask options for shuffle.DPCT1007:39: Migration of this CUDA API is not supported by the Intel(R) DPC++ Compatibility Tool.*/</code></pre></div><p>However, SYCL supports a rich set of functions for performing reductions. In this case, the reduce_over_group() function in SYCL can be used to create the same functionality as the above code as follows.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>#define REDUCEINTEGERSUM(value, pAccumulator)             int val = sycl::reduce_over_group(item_ct1.get_group(), value, std::plus&lt;&gt;());              *pAccumulator = val;             item_ct1.barrier(sycl::access::fence_space::local_space);</code></pre></div><p>The <em>sycl::reduce_over_group</em> is a collective function. The usage of this function simplifies the macro. The function takes the group, the value to be reduced, and the reduction operation which in this case is plus or summation. The function can adapt to varied sizes of work groups in SYCL and will use the best available optimizations available per the compiler and run-time.</p><h2>      Finding the minimum energy</h2><p>In another part of the application, a block of CUDA threads perform shuffles to find the minimum of scores <em>v0</em> and the corresponding identifier <em>k0</em> of the run in the simulation that is the minimum score. The CUDA code calls a macro WARPMINIMUM2 (not shown) which in turn calls another macro WARPMINIMUMEXCHANGE (shown) with <em>mask</em> set to 1, 2, 4, 8, and 16.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight cuda\"><code><span class=\"cp\">#define WARPMINIMUMEXCHANGE(tgx, v0, k0, mask)     </span>    <span class=\"p\">{</span>             <span class=\"kt\">float</span> <span class=\"n\">v1</span>    <span class=\"o\">=</span> <span class=\"n\">v0</span><span class=\"p\">;</span>             <span class=\"kt\">int</span> <span class=\"n\">k1</span>      <span class=\"o\">=</span> <span class=\"n\">k0</span><span class=\"p\">;</span>             <span class=\"kt\">int</span> <span class=\"n\">otgx</span>    <span class=\"o\">=</span> <span class=\"n\">tgx</span> <span class=\"o\">^</span> <span class=\"n\">mask</span><span class=\"p\">;</span>             <span class=\"kt\">float</span> <span class=\"n\">v2</span>    <span class=\"o\">=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">v0</span><span class=\"p\">,</span> <span class=\"n\">otgx</span><span class=\"p\">);</span>             <span class=\"kt\">int</span> <span class=\"n\">k2</span>      <span class=\"o\">=</span> <span class=\"n\">__shfl_sync</span><span class=\"p\">(</span><span class=\"mh\">0xffffffff</span><span class=\"p\">,</span> <span class=\"n\">k0</span><span class=\"p\">,</span> <span class=\"n\">otgx</span><span class=\"p\">);</span>             <span class=\"kt\">int</span> <span class=\"n\">flag</span>    <span class=\"o\">=</span> <span class=\"p\">((</span><span class=\"n\">v1</span> <span class=\"o\">&lt;</span> <span class=\"n\">v2</span><span class=\"p\">)</span> <span class=\"o\">^</span> <span class=\"p\">(</span><span class=\"n\">tgx</span> <span class=\"o\">&gt;</span> <span class=\"n\">otgx</span><span class=\"p\">))</span> <span class=\"o\">&amp;&amp;</span> <span class=\"p\">(</span><span class=\"n\">v1</span> <span class=\"o\">!=</span> <span class=\"n\">v2</span><span class=\"p\">);</span>             <span class=\"n\">k0</span>          <span class=\"o\">=</span> <span class=\"n\">flag</span> <span class=\"o\">?</span> <span class=\"n\">k1</span> <span class=\"o\">:</span> <span class=\"n\">k2</span><span class=\"p\">;</span>             <span class=\"n\">v0</span>          <span class=\"o\">=</span> <span class=\"n\">flag</span> <span class=\"o\">?</span> <span class=\"n\">v1</span> <span class=\"o\">:</span> <span class=\"n\">v2</span><span class=\"p\">;</span>         <span class=\"p\">}</span></code></pre></div><p>The <em>__shfl_sync</em> provides a way of moving a value from one thread to other threads in the warp in one instruction. In this code snippet <em>__shfl_sync</em> gets the <em>v0</em> or <em>k0</em> value from the thread identified by the <em>otgx</em> mask and saves it in <em>v2</em>, <em>k2</em> variables. We then compare <em>v1</em> with <em>v2</em> to set <em>flag</em> and eventually store the minimum in <em>v0</em> and the run identifier for this minimum in <em>k0</em>.</p><p>Compatibility Tool could not completely migrate this code and included this comment as the reason it could not. However, Compatibility Tool correctly replaced the <em>__shfl_sync</em> call with SYCL <em>shuffle</em> call as shown in the below diff which shows the manual change.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>/*DPCT1023:57: The DPC++ sub-group does not support mask options for shuffle.*/</code></pre></div><p>This comment indicates that the <em>shuffle</em> call in SYCL does not use a mask as shown below.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight diff\"><code><span class=\"err\">#define</span> WARPMINIMUMEXCHANGE(tgx, v0, k0, mask)             {                     float v1 = v0;                     int k1 = k0;                     int otgx = tgx ^ mask;     <span class=\"gd\">-               float v2 = item_ct1.get_sub_group().shuffle(energy, otgx);     </span><span class=\"gi\">+               float v2 = item_ct1.get_sub_group().shuffle(v0, otgx);  </span><span class=\"gd\">-               int k2 = item_ct1.get_sub_group().shuffle(bestID, otgx);     </span><span class=\"gi\">+               int k2 = item_ct1.get_sub_group().shuffle(k0, otgx);     </span>                int flag = ((v1 &lt; v2) ^ (tgx &gt; otgx)) &amp;&amp; (v1 != v2);                     k0 = flag ? k1 : k2;                     v0 = flag ? v1 : v2;             }</code></pre></div><p>In this case, Compatibility Tool performed incorrect variable substitution for <em>v0</em> and <em>k0</em> in the shuffle calls using <em>energy</em> and <em>bestID</em> variables from the caller function. We manually fixed this by replacing <em>energy</em> with <em>v0</em> and <em>bestID</em> with <em>k0</em>. This bug has been fixed in recent versions of the Compatibility Tool.</p><h2>      Summary</h2><p>In summary, reduction operations in CUDA applications may not be migrated correctly by the Compatibility Tool. Review the comments provided by the tool to understand if manual migration is necessary and what change might be required. A good understanding of the original CUDA code will then help to make manual changes to develop functionally correct code in SYCL.</p><p>[1] <a href=\"https://www.intel.com/content/www/us/en/docs/dpcpp-compatibility-tool/get-started-guide/2023-1/overview.html\">https://www.intel.com/content/www/us/en/docs/dpcpp-compatibility-tool/get-started-guide/2023-1/overview.html</a></p><p>[2] <a href=\"https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/\">https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/</a></p>",
            "url": "https://hpc.social/community-blog/2023/migrating-reduction-operations-to-sycl-in-a-molecular-docking-application/",
            
            
            
            
            
            "date_published": "2023-08-10T22:30:31-06:00",
            "date_modified": "2023-08-10T22:30:31-06:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/iwomp-2023/",
            "title": "IWOMP 2023",
            "summary": null,
            "content_text": "Sept. 12-15, 2023  The 19th International Workshop on OpenMP - IWOMP is the premier forum to present and discuss issues, trends, recent research ideas, and results related to parallel programming with OpenMP.The post IWOMP 2023 appeared first on OpenMP.",
            "content_html": "<p>Sept. 12-15, 2023  The 19th International Workshop on OpenMP - IWOMP is the premier forum to present and discuss issues, trends, recent research ideas, and results related to parallel programming with OpenMP.</p><p>The post <a href=\"https://www.openmp.org/events/iwomp-2021-2/\" rel=\"nofollow\">IWOMP 2023</a> appeared first on <a href=\"https://www.openmp.org\" rel=\"nofollow\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/iwomp-2023/",
            
            
            
            
            
            "date_published": "2023-07-17T21:35:36-06:00",
            "date_modified": "2023-07-17T21:35:36-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/supercomputing-2023/",
            "title": "Supercomputing 2023",
            "summary": null,
            "content_text": "November 12-16, 2023OpenMP will be in Denver for Supercomputing 2023 with four tutorials, a BOF, and more.The post Supercomputing 2023 appeared first on OpenMP.",
            "content_html": "<p>November 12-16, 2023<br />OpenMP will be in Denver for Supercomputing 2023 with four tutorials, a BOF, and more.</p><p>The post <a href=\"https://www.openmp.org/events/sc23/\" rel=\"nofollow\">Supercomputing 2023</a> appeared first on <a href=\"https://www.openmp.org\" rel=\"nofollow\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/supercomputing-2023/",
            
            
            
            
            
            "date_published": "2023-07-17T18:22:52-06:00",
            "date_modified": "2023-07-17T18:22:52-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/awesome-oneapi-announced/",
            "title": "Awesome oneAPI announced!",
            "summary": null,
            "content_text": "One of the ways that I feel we should engage when building community fora relatively new ecosystem like oneAPI is the ability to showcase it'scapabilities. We know that AI especially generative AI have capturedthe hearts and minds of many especially being able to build interestingvisuals using prompts. As well, GPU offloading, and learning algorithmsalso have gained traction in this space as well.We talk about the democratization ofAIand its important in the emerging new chapter of AI. There is no bettertime and greater need to build things on an open spec'd platform whereit's clear what is going and out and that the conversations are public,the decisions are public.An open spec'd platform is no good if it doesn't showutility. Developers aren't going to consume your platform if youcannot show viability, ease of use, and performance. So to show utility,we worked on building a curated list of projects that show examples ofthe utility of oneAPI, but also provide projects that are worth spendingtime being part of. Some of these projects might surprise you in thatthey use oneAPI like Blender.Some of you might have heard of the 'awesome' listsconcept which are lists of github repos that are greatexamples of using that subject matter. For instance, AwesomePytorch is a goodexample of a list that shows cool projects that use pytorch. The listis meant to be simple, developer friendly, and easy to navigate.We were inspired by these lists as they seem like a great way to find yourway to good projects. So we created our own 'awesome' list of projectsfor SYCL and oneAPI. So without further ado, feel free to check outawesome oneAPI. Wewould of course love feedback and if you have projects that might fitthis list, please fork and submit a PR! Questions are welcome, you canreach me on mastodon at @sri@mast.hpc.social or if you're on dev.to -just hit the comments!",
            "content_html": "<p>One of the ways that I feel we should engage when building community for<br />a relatively new ecosystem like oneAPI is the ability to showcase it's<br />capabilities. We know that AI especially generative AI have captured<br />the hearts and minds of many especially being able to build interesting<br />visuals using prompts. As well, GPU offloading, and learning algorithms<br />also have gained traction in this space as well.</p><p>We talk about the <a href=\"https://www.turing.com/kb/ultimate-guide-to-democratization-in-ai\">democratization of<br />AI</a><br />and its important in the emerging new chapter of AI. There is no better<br />time and greater need to build things on an open spec'd platform where<br />it's clear what is going and out and that the conversations are public,<br />the decisions are public.</p><p>An open spec'd platform is no good if it doesn't show<br /><em>utility</em>. Developers aren't going to consume your platform if you<br />cannot show viability, ease of use, and performance. So to show utility,<br />we worked on building a curated list of projects that show examples of<br />the utility of oneAPI, but also provide projects that are worth spending<br />time being part of. Some of these projects might surprise you in that<br />they use oneAPI like Blender.</p><p>Some of you might have heard of the 'awesome' lists<br />concept which are lists of github repos that are great<br />examples of using that subject matter. For instance, <a href=\"https://github.com/bharathgs/Awesome-pytorch-list\">Awesome<br />Pytorch</a> is a good<br />example of a list that shows cool projects that use pytorch. The list<br />is meant to be simple, developer friendly, and easy to navigate.</p><p>We were inspired by these lists as they seem like a great way to find your<br />way to good projects. So we created our own 'awesome' list of projects<br />for SYCL and oneAPI. So without further ado, feel free to check out<br /><a href=\"https://github.com/oneapi-community/awesome-oneapi\">awesome oneAPI</a>. We<br />would of course love feedback and if you have projects that might fit<br />this list, please fork and submit a PR! Questions are welcome, you can<br />reach me on mastodon at @<a href=\"mailto:sri@mast.hpc.social\">sri@mast.hpc.social</a> or if you're on dev.to -<br />just hit the comments!</p>",
            "url": "https://hpc.social/community-blog/2023/awesome-oneapi-announced/",
            
            
            
            
            
            "date_published": "2023-06-22T20:37:53-06:00",
            "date_modified": "2023-06-22T20:37:53-06:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/the-hpc-social-project-talk-at-easybuild-users-meeting/",
            "title": "The hpc.social project - talk at EasyBuild Users Meeting",
            "summary": null,
            "content_text": "In case you missed it, Alan and vsochpresented the hpc.social at the annual EasyBuild User’s meeting:In this talk they share the origins of the project, the current project, andprompt for questions or ideas about desire for the future. As a result of the talk,the hpc.social events page has already been refactoredto properly show the HPC Huddle community feed, and other communities that have icalfeeds are welcome to contribute their event feeds there.",
            "content_html": "<p>In case you missed it, <a href=\"https://github.com/alansill\">Alan</a> and <a href=\"https://github.com/vsoch\">vsoch</a>presented the hpc.social at the annual EasyBuild User’s meeting:</p><p>In this talk they share the origins of the project, the current project, andprompt for questions or ideas about desire for the future. As a result of the talk,the <a href=\"https://hpc.social/events/\">hpc.social events</a> page has already been refactoredto properly show the HPC Huddle community feed, and other communities that have icalfeeds are welcome to contribute their event feeds there.</p>",
            "url": "https://hpc.social/community-blog/2023/the-hpc-social-project-talk-at-easybuild-users-meeting/",
            
            
            
            
            
            "date_published": "2023-05-01T00:00:00-06:00",
            "date_modified": "2023-05-01T00:00:00-06:00",
            
                "author": "hpc.social"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/openmp-arb-adds-new-member-samsung/",
            "title": "OpenMP® ARB adds new member Samsung",
            "summary": null,
            "content_text": "The OpenMP Architecture Review Board (ARB) today announced that Samsung has joined the board.The post OpenMP® ARB adds new member Samsung appeared first on OpenMP.",
            "content_html": "<p>The OpenMP Architecture Review Board (ARB) today announced that Samsung has joined the board.</p><p>The post <a href=\"https://www.openmp.org/press-release/openmp-arb-adds-new-member-samsung/\" rel=\"nofollow\">OpenMP® ARB adds new member Samsung</a> appeared first on <a href=\"https://www.openmp.org\" rel=\"nofollow\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/openmp-arb-adds-new-member-samsung/",
            
            
            
            
            
            "date_published": "2023-04-13T12:00:36-06:00",
            "date_modified": "2023-04-13T12:00:36-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/using-oneapi-ai-toolkits-from-intel-and-accenture-part-2/",
            "title": "Using oneAPI AI Toolkits from Intel and Accenture Part 2",
            "summary": null,
            "content_text": "      IntroductionThis is part 2 of our blog series. These posts are really about inspiring others to think of cool projects to do with oneAPI. In the last blog post, we discussed several toolkits that I thought were interesting. If someone produced an idea that uses those toolkits – I would love to know!!In this blog post, I want to focus on two other AI toolkits and how to use them. There is one other aspect that we should consider when looking at these toolkits: what do you believe might be unintended consequences?? As an exercise, I am going to go over these toolkits, but I would love to hear what you might believe are unintended consequences that have the potential to be overlooked.       Personalized Retail Experiences with Enhanced Customer SegmentationAccenture has over 30 toolkits to showcase oneAPI, with more to come.  In this post, I am going to look at this idea of using AI to personalize your shopping experience. I think all of us who do any kind of online shopping know the importance of providing a personalized shopping experience. First, we must understand how one might implement a personal shopping experience. Today, retailers have an incredible amount of data at their disposal. The analytics market is worth up to $20 billion around the world and is growing at a 19.3 percent Compound Annual Growth Rate (CAGR). Retailers are eager to understand customer behavior so that they can provide a better shopping experience and thus drive brand loyalty. To access the AI toolkit clone the github repository:$ git clone https://github.com/oneapi-src/customer-segmentationThe reference kit will show how to analyze customer purchasing data and segment it into clusters based on customer behavior. It will also show you how to optimize the reference solution using the Intel Scikit-Learn extension.The reference example uses an experimental dataset. The dataset is a set of 500k transactions covering 4000 customers from a UK multinational online retailer over a period of a year. The dataset is fed into KMeans and DBSCAN algorithms to label cluster based on different customer behaviors.Try it out and send me some feedback. Also, keep in mind the challenge of what could go wrong. (disclaimer: I don’t know myself - I’m curious to hear theories)      Faster session Notes with Speech-to-Text AI for Healthcare ProvidersMy second example is going back to healthcare. Always a fun one. The same challenge as in the previous one.The premise for this is that mental health providers are required to document their sessions using progress notes. These recorded sessions then need to be transcribed into written notes, and be stored for later reference.Managing these notes can take quite a bit of time. The idea, then, is to take these recorded notes and feed them to a speech-to-text AI algorithm and provide a summary. This summary can then be used to coordinate care, creating a paper trail, compliance, and keeping track of the state of the client.By reducing the book keeping, a therapist would have more time for their patients or the capacity to see more patients. Given the shortage of mental health professionals, being able to be more efficient and allowing more “human”contact  time will help mental health professionals provide their clients with better care.You can find the code for this implementation at:$ git clone  https://github.com/oneapi-src/ai-transcribeThe high level overview of this implementation is something like this. The conversion from speech to text is achieved by using a sequence-to-sequence framework called Fairseq. Sequence-to-sequence modeling is a type of machine learning that is commonly built to create summaries, text translations and so on. It was initially conceived by Google. Fairseq is an open source  sequence-to-sequence framework from Facebook.The process is described like this:Take your dataset of unstructured audio samplesRun it through a data preprocessing using Fairseq modelingUsing GAN you create a trained model using both the training data and the pre-processing data.Apply inference to generate the text.I think one of the more interesting parts of this pipeline is the GAN - which is described as two algorithms: one as a generator and the other as a test. The two work against each other until they both end up with the same dataset that, ostensibly, is accurate.One other piece that is missing as part of training the algorithm is a database of English text corpus data. This database contains speech audio files and text transcription. It is used to create a relationship between an audio signal and phonemes as part of speech recognition.Where GAN comes in is that a neural network is trained to generate what it thinks are the representations of the phonemes as opposed to the real world data obtained from the corpus data. The other neural network is trained on the corpus data and acts as the validator - as the two neural networks work with each other - the generator portion of the neural network will finally produce the results as expected by the other neural network.It is through this that we can validate that the output is correct.The entire software to do this is all open source - I would love to hear from people who have tried it and share what their results were!I think it would be interesting to train this with humans to determine how accurate it is so you can fully train the corpus and generator algorithm for better results.      SummaryI’ve reviewed two Accenture toolkits that demonstrate how AI can be used practically with real examples. Being a newcomer in this area, there is so much that I don’t know. Ironically, I use chatGPT to help explain some of the salient bits about how GAN works vis-a-vis audio data to really understand what was happening, especially in regards to mapping with words and phonemes.Looking forward to people’s responses to this post and enjoying a great conversation about AI, its potential uses and applications by using real world examples.      Call to ActionHas this blog post inspired you to write something based on the oneAPI AI toolkits? Let me know - I would love to know how it works out for you!",
            "content_html": "<h2>      Introduction</h2><p>This is part 2 of our blog series. These posts are really about inspiring others to think of cool projects to do with oneAPI. In the last blog post, we discussed several toolkits that I thought were interesting. If someone produced an idea that uses those toolkits – I would love to know!!<br />In this blog post, I want to focus on two other AI toolkits and how to use them. <br />There is one other aspect that we should consider when looking at these toolkits: what do you believe might be unintended consequences?? As an exercise, I am going to go over these toolkits, but I would love to hear what you might believe are unintended consequences that have the potential to be overlooked. </p><h2>      Personalized Retail Experiences with Enhanced Customer Segmentation</h2><p>Accenture has over 30 toolkits to showcase oneAPI, with more to come.  In this post, I am going to look at this idea of using AI to personalize your shopping experience. I think all of us who do any kind of online shopping know the importance of providing a personalized shopping experience. First, we must understand how one might implement a personal shopping experience. <br />Today, retailers have an incredible amount of data at their disposal. The analytics market is worth up to $20 billion around the world and is growing at a 19.3 percent Compound Annual Growth Rate (CAGR). Retailers are eager to understand customer behavior so that they can provide a better shopping experience and thus drive brand loyalty. </p><p>To access the AI toolkit clone the github repository:<br /></p><p><code>$ git clone https://github.com/oneapi-src/customer-segmentation</code><br /></p><p>The reference kit will show how to analyze customer purchasing data and segment it into clusters based on customer behavior. It will also show you how to optimize the reference solution using the Intel Scikit-Learn extension.</p><p>The reference example uses an experimental dataset. The dataset is a set of 500k transactions covering 4000 customers from a UK multinational online retailer over a period of a year. The dataset is fed into <a href=\"https://en.wikipedia.org/wiki/K-means_clustering\">KMeans</a> and <a href=\"https://en.wikipedia.org/wiki/DBSCAN\">DBSCAN</a> algorithms to label cluster based on different customer behaviors.</p><p>Try it out and send me some feedback. Also, keep in mind the challenge of what could go wrong. (disclaimer: I don’t know myself - I’m curious to hear theories)</p><h2>      Faster session Notes with Speech-to-Text AI for Healthcare Providers</h2><p>My second example is going back to healthcare. Always a fun one. The same challenge as in the previous one.</p><p>The premise for this is that mental health providers are required to document their sessions using progress notes. These recorded sessions then need to be transcribed into written notes, and be stored for later reference.</p><p>Managing these notes can take quite a bit of time. The idea, then, is to take these recorded notes and feed them to a speech-to-text AI algorithm and provide a summary. This summary can then be used to coordinate care, creating a paper trail, compliance, and keeping track of the state of the client.</p><p>By reducing the book keeping, a therapist would have more time for their patients or the capacity to see more patients. Given the shortage of mental health professionals, being able to be more efficient and allowing more “human”contact  time will help mental health professionals provide their clients with better care.</p><p>You can find the code for this implementation at:<br /></p><p><code>$ git clone  https://github.com/oneapi-src/ai-transcribe</code><br /></p><p>The high level overview of this implementation is something like this. The conversion from speech to text is achieved by using a sequence-to-sequence framework called Fairseq. Sequence-to-sequence modeling is a type of machine learning that is commonly built to create summaries, text translations and so on. It was initially conceived by Google. <a href=\"https://github.com/facebookresearch/fairseq\">Fairseq</a> is an open source  sequence-to-sequence framework from Facebook.</p><p>The process is described like this:</p><ul><li>Take your dataset of unstructured audio samples</li><li>Run it through a data preprocessing using Fairseq modeling</li><li>Using <a href=\"https://www.geeksforgeeks.org/generative-adversarial-network-gan/\">GAN</a> you create a trained model using both the training data and the pre-processing data.</li><li>Apply <a href=\"https://www.datacamp.com/blog/what-is-machine-learning-inference\">inference</a> to generate the text.</li></ul><p>I think one of the more interesting parts of this pipeline is the GAN - which is described as two algorithms: one as a generator and the other as a test. The two work against each other until they both end up with the same dataset that, ostensibly, is accurate.</p><p>One other piece that is missing as part of training the algorithm is a database of English text corpus data. This database contains speech audio files and text transcription. It is used to create a relationship between an audio signal and phonemes as part of speech recognition.</p><p>Where GAN comes in is that a neural network is trained to generate what it thinks are the representations of the phonemes as opposed to the real world data obtained from the corpus data. The other neural network is trained on the corpus data and acts as the validator - as the two neural networks work with each other - the generator portion of the neural network will finally produce the results as expected by the other neural network.</p><p>It is through this that we can validate that the output is correct.</p><p>The entire software to do this is all open source - I would love to hear from people who have tried it and share what their results were!</p><p>I think it would be interesting to train this with humans to determine how accurate it is so you can fully train the corpus and generator algorithm for better results.</p><h2>      Summary</h2><p>I’ve reviewed two Accenture toolkits that demonstrate how AI can be used practically with real examples. Being a newcomer in this area, there is so much that I don’t know. Ironically, I use chatGPT to help explain some of the salient bits about how GAN works vis-a-vis audio data to really understand what was happening, especially in regards to mapping with words and phonemes.</p><p>Looking forward to people’s responses to this post and enjoying a great conversation about AI, its potential uses and applications by using real world examples.</p><h2>      Call to Action</h2><p>Has this blog post inspired you to write something based on the oneAPI AI toolkits? Let me know - I would love to know how it works out for you!</p>",
            "url": "https://hpc.social/community-blog/2023/using-oneapi-ai-toolkits-from-intel-and-accenture-part-2/",
            
            
            
            
            
            "date_published": "2023-03-31T23:21:33-06:00",
            "date_modified": "2023-03-31T23:21:33-06:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/training-ai-with-oneapi-part-1/",
            "title": "Training AI with oneAPI part 1",
            "summary": null,
            "content_text": "      oneAPI and AIMy last few blog posts were pretty fun to write. I'm going to change subjects today and talk about AI. We'll learn about what resources are around for those of you who know the particulars about AI and want to start a project, but are interested in delving deeper into the capabilities.       Accenture and IntelIt should be no surprise that Intel is the largest stakeholder in oneAPI, if you've done any kind of research on oneAPI at all. Intel's interest is creating a performative software stack that runs well, not just on Intel platforms, but on any platform. oneAPI's purpose is to be able to take advantage of all the hardware you have on your system and not just the GPU or CPU. Let's talk about oneAPI and the AI toolkits that have been released over the past 8 months or so. Intel worked with Accenture to release some open source \"recipes\" for AI. If you've always wanted to delve into AI but have problems on starting a project - this is a great place to ponder what kind of a project you'd want to write based on what problems it solves. These AI kits are a one-stop shop of everything you'd need to get started, including the training data!       oneAPI AI ToolkitsThe Intel and Accenture tool kits are all released as open source and can be found on github. The tool kits span a number of industries from telecommunications to health &amp; life sciences to retail and more. They provide a great showcase on how AI is being used today in different industries and what problems they are solving. The best part of these tool kits is how comprehensive they are. You'll have everything you need to get the toolkit working smoothly, including the source code and training data. In this blog post, I'll focus on two reference kits and explain how they work. The github page for them is fairly self-explanatory but it's still worth going over them.       Disease PredictionThe first reference kit is disease prediction. This toolkit will look through patient records and look for a possible disease indication. The interesting part of this is the use of NLP (Natural Language Processing) to sort through unstructured data located in patient records. NLP has been used by healthcare for quite some time - but only now has there been significant investment by healthcare payers. NLP can be used in other areas as well. For instance, understanding what kind of dosage of medication that a patient should take based on their particular genetics! By training on the data of millions of patients, one could really understand the unique properties of the health of individuals and act accordingly. There is also an interesting social change - the ability to objectively look at patients and their needs, especially women's health needs, means that we can create prediction models based on symptoms that can be followed up on. It's possible to reduce bias in care through such a system - as long as the AI employed is not biased. To actually pore through patient records, you'd need an NLP that is already pre-trained on reading words. Normally, you'd have to have an algorithm and then use a large number of data sets to get to a point where you'd be able to read natural language. This is why they use the BERT language model. More accurately, a specialized form of BERT called clinicalBERT which includes clinical jargon and medical references. If you've followed the text of the github repo - the process is pretty simple.  You have the clinicalBERT language model which you would use to train your AI using the data from clinical records. The language model then creates an association with symptoms to predicted disease probabilities. Now you have a model that you can apply to any set of symptoms with an output of predicted probabilities. The process of applying data to a model is called model inference We won't go through the process of building the software and training it here. The repo has some clear steps in how to train your model. The prerequisites require Python and PyTorch v1.11. The repo also goes on to describe how to optionally use the Intel extensions for Python for better performance. I'd like to also add that these extensions exist temporarily while the process of upstreaming to main line python continues. Rather than wait, the community can enjoy the optimizations now, rather than at some future date. There are some instructions to do some bench marking - if you're interested in seeing how well it works on various other platforms.       Increase Mortgage Loan Default Risk Prediction SpeedNext, I'll focus on banking and loans. Banks use AI prediction models to determine risk. This is an interesting case study and I'd like to see some comments about this particular scenario because I expect that some of you will have opinions! The problem statement here is that in Q4 2021, mortgage delinquencies were 4.65% and outstanding balances of unpaid principals was approximately $2.6 trillion dollars. The average time to complete a foreclosure process was 941 days, leading to a result of approximately $7.6 billion in foreclosure costs alone. What this kit offers is the ability to manage default risk, handle larger data sets, and reduce the underwriting wait time. The kit will improve customer service quality and speed up loan processing. So, let's take a look at the github repo for Loan Default Risk Prediction using XGBoost. This reference solution follows a similar idea. XGBoost XBoost is part of a family of machine learning algorithms that uses decision trees. Specifically, XGBoost uses gradient boosting which instead of using one decision tree, it uses an ensemble of decision trees. A decision tree is nothing more than a model that tries to make a prediction basted on a selection of data. With that background in mind, you can look at the intended data set that is being used with the kind of parameters. To make it even more interesting, a modification was made to the data set by adding synthetic bias_variable. The idea is to add bias value for each loan - the value is generated randomly. The reason is to demonstrate bias between a protected class and a privileged class. It isn't used as part of training the model. Another thing that's wonderful about this AI toolkit is how it demonstrates bias model. The section about \"Fairness Evaluation\" goes into some length about whether the algorithm is fair. This is an important consideration when training AI models and is an area of active research. While AI can be a powerful tool, it can also be a tool that can augment inequalities and inequities and, when used in decision making, can exacerbate and preserve these existing inequalities. To use the toolkit, you'll need Python v3.9 and XGBoost v0.81 and clone the repo:git clone https://www.github.com/oneapi-src/loan-default-risk-predictionuse the bash script to set up the environment. Follow the instructions in the repo on how to get the model running. I will leave it up to the reader to run this model. Specifically run it many times and observe the fairness metric and see how that changes.       Call to ActionWhat do you think about the ease of using these tool kits so far? I would love to hear your thoughts and see if the results were intriguing to you. The bias factor in the last AI toolkit is something that intrigues me - is the model of fairness really fair? How would you change any of these models? Hit me up on the comments, let's have a conversation! ",
            "content_html": "<h2>      oneAPI and AI</h2><p>My last few blog posts were pretty fun to write. I'm going to change subjects today and talk about AI. We'll learn about what resources are around for those of you who know the particulars about AI and want to start a project, but are interested in delving deeper into the capabilities. </p><h2>      Accenture and Intel</h2><p>It should be no surprise that Intel is the largest stakeholder in oneAPI, if you've done any kind of research on oneAPI at all. Intel's interest is creating a performative software stack that runs well, not just on Intel platforms, but on any platform. oneAPI's purpose is to be able to take advantage of all the hardware you have on your system and not just the GPU or CPU. </p><p>Let's talk about oneAPI and the AI toolkits that have been released over the past 8 months or so. Intel worked with Accenture to release some open source \"recipes\" for AI. If you've always wanted to delve into AI but have problems on starting a project - this is a great place to ponder what kind of a project you'd want to write based on what problems it solves. These AI kits are a one-stop shop of everything you'd need to get started, including the training data! </p><h2>      oneAPI AI Toolkits</h2><p>The Intel and Accenture tool kits are all released as open source and can be found on github. The tool kits span a number of industries from telecommunications to health &amp; life sciences to retail and more. They provide a great showcase on how AI is being used today in different industries and what problems they are solving. </p><p>The best part of these tool kits is how comprehensive they are. You'll have everything you need to get the toolkit working smoothly, including the source code and training data. </p><p>In this blog post, I'll focus on two reference kits and explain how they work. The github page for them is fairly self-explanatory but it's still worth going over them. </p><h2>      Disease Prediction</h2><p>The first reference kit is <a href=\"https://github.com/oneapi-src/disease-prediction\">disease prediction</a>. This toolkit will look through patient records and look for a possible disease indication. The interesting part of this is the use of NLP (Natural Language Processing) to sort through unstructured data located in patient records. </p><p>NLP has been used by healthcare for quite some time - but only now has there been significant investment by healthcare payers. NLP can be used in other areas as well. For instance, understanding what kind of dosage of medication that a patient should take based on their particular genetics! By training on the data of millions of patients, one could really understand the unique properties of the health of individuals and act accordingly. </p><p>There is also an interesting social change - the ability to objectively look at patients and their needs, especially women's health needs, means that we can create prediction models based on symptoms that can be followed up on. It's possible to reduce bias in care through such a system - as long as the AI employed is not biased. </p><p>To actually pore through patient records, you'd need an NLP that is already pre-trained on reading words. Normally, you'd have to have an algorithm and then use a large number of data sets to get to a point where you'd be able to read natural language. This is why they use the <a href=\"https://en.wikipedia.org/wiki/BERT_(language_model)\">BERT</a> language model. More accurately, a specialized form of BERT called clinicalBERT which includes clinical jargon and medical references. </p><p>If you've followed the text of the github repo - the process is pretty simple.  </p><ul><li><p>You have the clinicalBERT language model which you would use to train your AI using the data from clinical records. </p></li><li><p>The language model then creates an association with symptoms to predicted disease probabilities. </p></li><li><p>Now you have a model that you can apply to any set of symptoms with an output of predicted probabilities. </p></li><li><p>The process of applying data to a model is called <em>model inference</em> </p></li></ul><p>We won't go through the process of building the software and training it here. The <a href=\"https://github.com/oneapi-src/disease-prediction\">repo</a> has some clear steps in how to train your model. </p><p>The prerequisites require Python and PyTorch v1.11. The repo also goes on to describe how to optionally use the Intel extensions for Python for better performance. I'd like to also add that these extensions exist temporarily while the process of upstreaming to main line python continues. Rather than wait, the community can enjoy the optimizations now, rather than at some future date. </p><p>There are some instructions to do some bench marking - if you're interested in seeing how well it works on various other platforms. </p><h2>      Increase Mortgage Loan Default Risk Prediction Speed</h2><p>Next, I'll focus on banking and loans. Banks use AI prediction models to determine risk. This is an interesting case study and I'd like to see some comments about this particular scenario because I expect that some of you will have opinions! </p><p>The problem statement here is that in Q4 2021, mortgage delinquencies were 4.65% and outstanding balances of unpaid principals was approximately $2.6 trillion dollars. The average time to complete a foreclosure process was 941 days, leading to a result of approximately $7.6 billion in foreclosure costs alone. </p><p>What this kit offers is the ability to manage default risk, handle larger data sets, and reduce the underwriting wait time. The kit will improve customer service quality and speed up loan processing. </p><p>So, let's take a look at the github repo for <a href=\"https://github.com/oneapi-src/loan-default-risk-prediction\">Loan Default Risk Prediction using XGBoost</a>. </p><p>This reference solution follows a similar idea. <a href=\"https://en.wikipedia.org/wiki/XGBoost\">XGBoost</a> XBoost is part of a family of machine learning algorithms that uses decision trees. Specifically, XGBoost uses <a href=\"https://en.wikipedia.org/wiki/Gradient_boosting\">gradient boosting</a> which instead of using one decision tree, it uses an ensemble of <a href=\"https://en.wikipedia.org/wiki/Decision_tree_learning\">decision trees</a>. A decision tree is nothing more than a model that tries to make a prediction basted on a selection of data. </p><p>With that background in mind, you can look at the intended data set that is being used with the kind of parameters. </p><p>To make it even more interesting, a modification was made to the data set by adding synthetic bias_variable. The idea is to add bias value for each loan - the value is generated randomly. The reason is to demonstrate bias between a protected class and a privileged class. It isn't used as part of training the model. </p><p>Another thing that's wonderful about this AI toolkit is how it demonstrates bias model. The section about \"Fairness Evaluation\" goes into some length about whether the algorithm is fair. This is an important consideration when training AI models and is an area of active research. While AI can be a powerful tool, it can also be a tool that can augment inequalities and inequities and, when used in decision making, can exacerbate and preserve these existing inequalities. </p><p>To use the toolkit, you'll need Python v3.9 and XGBoost v0.81 and clone the repo:<br /></p><p><code>git clone https://www.github.com/oneapi-src/loan-default-risk-prediction</code><br /></p><p>use the bash script to set up the environment. </p><p>Follow the instructions in the repo on how to get the model running. </p><p>I will leave it up to the reader to run this model. Specifically run it many times and observe the fairness metric and see how that changes. </p><h2>      Call to Action</h2><p>What do you think about the ease of using these tool kits so far? I would love to hear your thoughts and see if the results were intriguing to you. The bias factor in the last AI toolkit is something that intrigues me - is the model of fairness really fair? How would you change any of these models? </p><p>Hit me up on the comments, let's have a conversation! </p>",
            "url": "https://hpc.social/community-blog/2023/training-ai-with-oneapi-part-1/",
            
            
            
            
            
            "date_published": "2023-03-30T05:54:13-06:00",
            "date_modified": "2023-03-30T05:54:13-06:00",
            
                "author": "oneAPI Community Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/sifive-joins-the-openmp-effort/",
            "title": "SiFive joins the OpenMP® effort",
            "summary": null,
            "content_text": "SiFive joins the OpenMP Architecture Review Board (ARB), a group of leading hardware vendors, software vendors and research organizations, in creating the standard for the most popular shared-memory parallel programming model in use today.The post SiFive joins the OpenMP® effort appeared first on OpenMP.",
            "content_html": "<p>SiFive joins the OpenMP Architecture Review Board (ARB), a group of leading hardware vendors, software vendors and research organizations, in creating the standard for the most popular shared-memory parallel programming model in use today.</p><p>The post <a href=\"https://www.openmp.org/press-release/sifive-joins-the-openmp-effort/\" rel=\"nofollow\">SiFive joins the OpenMP® effort</a> appeared first on <a href=\"https://www.openmp.org\" rel=\"nofollow\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/sifive-joins-the-openmp-effort/",
            
            
            
            
            
            "date_published": "2023-03-14T09:00:24-06:00",
            "date_modified": "2023-03-14T09:00:24-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/embedded-systems-and-the-openmp-api/",
            "title": "Embedded Systems and the OpenMP® API",
            "summary": null,
            "content_text": "Embedded systems are used in fields as diverse as telecommunication systems, robotics, automotive, and medical applications. They are very heterogeneous and consist of multicore systems and accelerators.The post Embedded Systems and the OpenMP® API appeared first on OpenMP.",
            "content_html": "<p>Embedded systems are used in fields as diverse as telecommunication systems, robotics, automotive, and medical applications. They are very heterogeneous and consist of multicore systems and accelerators.</p><p>The post <a href=\"https://www.openmp.org/blog/embedded-systems-and-the-openmp-api/\" rel=\"nofollow\">Embedded Systems and the OpenMP® API</a> appeared first on <a href=\"https://www.openmp.org\" rel=\"nofollow\">OpenMP</a>.</p>",
            "url": "https://hpc.social/community-blog/2023/embedded-systems-and-the-openmp-api/",
            
            
            
            
            
            "date_published": "2023-03-14T09:00:22-06:00",
            "date_modified": "2023-03-14T09:00:22-06:00",
            
                "author": "OpenMP Blog"
            
        },
    
        {
            "id": "https://hpc.social/community-blog/2023/modern-software-development-tools-and-oneapi-part-3/",
            "title": "Modern Software Development Tools and oneAPI Part 3",
            "summary": null,
            "content_text": "This is the third part in the series. Part 1 is here and Part 2 is here.Welcome to the third, and likely the final, post in this blog series! To recap, in the last blog post we talked about build systems particularly meson Before that, we talked about building a container that contains the pure open source elements of the oneAPI developer environment and use it to build a simple oneAPI SYCL program.In this post, we're going to take our key learnings from the last two blog posts and use them to build a true user-friendly experience where you can write code using a modern IDE and compile and run them inside a container like you might be used to on other platforms like Windows and MacOS.First, allow us to introduce you to this modern IDE - 'GNOME Builder'. GNOME Builder is an IDE developed for GNOME desktop. It is integrated to be able to write GNOME and GTK applications easily with all the modern features one would expect from a IDE, and then some.It has an impressive set of features - the author, Christian Hergert, wrote it because he was [frustrated (https://foundation.gnome.org/2015/01/09/interview-with-christian-hergert-about-builder-an-ide-for-gnome-2/)  with the state of IDEs on the Linux platform. GNOME Builder is not just an IDE, but a complete showcase of what a non-trivial application written in GNOME can do.This blog post is about oneAPI - why use an IDE that is optimized for using GNOME to build applications?Great question. The desktop ecosystem (GNOME and KDE has been focused on distribution of apps through a container technology called flatpak. Flatpak allows you to have an runtime that contains everything to run a GNOME (or KDE) application. There is an associated SDK that contains all the tools needed to build the application. GNOME Builder is the first IDE that integrates this idea of containerized applications into the user experience. With Builder, you only need the application - you don't need a compiler, profiler, or development libraries - it integrates all that inside a container. This means that you don't need to think about how to setup a developer environment for any GNOME application.The containers in the past have been flatpak based containers. But it turns out that you can leverage GNOME Builder to use any container created by podman, toolbox, or distrobox.In essence, the first blog post in this series mimicked what flatpak already does: which is a container that contains everything you need to build an oneAPI application/program instead of a GNOME one.In a bit of circularity that you might find amusing - we will use flatpak to get the application and then use another comtainer to build our sample application that uses Meson.If you have not read the first two blog posts, this might be a good time to stop and read those first because we'll be using the container we created in the first blog post and the build system we used in the second blog post. It's also important  you  use a distro like Fedora or openSUSE that supports flatpak out of the box.With the pre-requisites out of the way, let's first start by installing GNOME Builder. You can use any desktop you want, but I will be using GNOME here as it is what I usually run, please translate accordingly.Here are the steps:First make sure you add the flathub flatpak respository:$  flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepoInstall GNOME Builder:$ flatpak install flathub org.gnome.BuilderRun GNOME builder either through your desktop launch options. For GNOME, hit the meta key (usually Windows key) and then type in \"Builder\" - GNOME Builder should be your first,  and likely only, option. You can also run it from the command line:,$ flatpak run org.gnome.BuilderYou should now have GNOME Builder running on your machine!      Creating a ProjectThe first step is to create a project.Select \"Create New Project...\" You will be presented with a new screen where you put in the details for the project. Let's call our project \"oneapi-simple\".Next we need to select the application-id. Application-ids are generally a reverse DNS type of string usually based on a hostname. I have my own domain, so I usually use that. But you can use whateer you like. In this case, I am going to use me.ramkrishna.oneapisimple.We want to use C++, so under Language change it to C++. Note that the Template section has now changed to 'Command Line Tool' Which is exactly what we want.Here is a filled-out screenshot of the window from Builder:We now create the project! Selected the \"Create Project\" and we are now ready to continue.GNOME Builder has two sections - the sidebar and the main editor window. The side bar will have our files and so click on \"src\" and you should see two files - main.cpp and meson.buid.      Setup the build systemYou will notice that the project is already set up to use meson by default. Meson is the preferred build system for GNOME. Meson was created by someone from the GNOME community and thus is already well trusted. In the application space, meson has proven to be quite popular replacement for autotools.Let's leave main.cpp alone for now, and focus on meson.build. If you click on meson.build, you'll see that it looks like this:oneapi_simple_sources = [  'main.cpp',]oneapi_simple_deps = []executable('oneapi-simple', oneapi_simple_sources,  dependencies: oneapi_simple_deps,  install: true,)This meson.build is set up to compile a generic project with the g++ compiler. So that's not going to work. If you read the previous blog post, we went through what we would need to make it work with the SYCL compiler.Replace the contents of meson.build with this:simple_oneapi_sources = files('main.cpp')simple_oneapi_deps = []executable('simple-oneapi', simple_oneapi_sources,  link_args:'-fsycl',  cpp_args:'-fsycl',  dependencies: simple_oneapi_deps,  install: true, install_dir: '/var/home/sri/Projects/oneapi-simple/bin')For the SYCL compiler, we need some extra linker flags. We're actually missing something even more important and that's the setup for the compiler itself!Click on the 'meson.build' file in the top level - which should be right next to the 'COPYING' file. You'll notice that every time you open a new file, it creates a new tab in the editor view. You can easily switch to each file by clicking on the tab.Let's take a look at it. It should look like this.project('oneapi-simple', ['cpp', 'c'],          version: '0.1.0',    meson_version: '&gt;= 0.59.0',  default_options: [ 'warning_level=2', 'werror=false', 'cpp_std=gnu++2a', ],)subdir('src')The important part here is that we are identifying that this project is C++. All of this is correct and there is nothing more to be done.      Set up our sourceNow, that we have the build set up. It's time to replace the code in main.cpp. Currently, the code looks like:#include &lt;iostream&gt;int main() {    std::cout &lt;&lt; \"Hello World\\n\";    return 0;}We are going to replace it with:#include &lt;sycl/sycl.hpp&gt;int main() {  // Creating buffer of 4 ints to be used inside the kernel code  sycl::buffer&lt;sycl::cl_int, 1&gt; Buffer(4);  // Creating SYCL queue  sycl::queue Queue;  // Size of index space for kernel  sycl::range&lt;1&gt; NumOfWorkItems{Buffer.size()};  // Submitting command group(work) to queue  Queue.submit([&amp;](sycl::handler &amp;cgh) {    // Getting write only access to the buffer on a device    auto Accessor = Buffer.get_access&lt;sycl::access::mode::write&gt;(cgh);    // Executing kernel    cgh.parallel_for&lt;class FillBuffer&gt;(        NumOfWorkItems, [=](sycl::id&lt;1&gt; WIid) {          // Fill buffer with indexes          Accessor[WIid] = (sycl::cl_int)WIid.get(0);        });  });  // Getting read only access to the buffer on the host.  // Implicit barrier waiting for queue to complete the work.  const auto HostAccessor = Buffer.get_access&lt;sycl::access::mode::read&gt;();  // Check the results  bool MismatchFound = false;  for (size_t I = 0; I &lt; Buffer.size(); ++I) {    if (HostAccessor[I] != I) {      std::cout &lt;&lt; \"The result is incorrect for element: \" &lt;&lt; I                &lt;&lt; \" , expected: \" &lt;&lt; I &lt;&lt; \" , got: \" &lt;&lt; HostAccessor[I]                &lt;&lt; std::endl;      MismatchFound = true;    }  }  if (!MismatchFound) {    std::cout &lt;&lt; \"The results are correct!\" &lt;&lt; std::endl;  }  return MismatchFound;}OK - now we have everything. But we can't quite compile yet. Right now, if you tried to compile this - it won't work. The reason is, the build is currently set up for native build'. Which means it will try to use the toolchain on the host system. On the host system, we don't have any of the oneAPI libraries or the SYCL compiler. So it won't find anything. Everything we wanted is encapsulated in a container.This is why GNOME Builder is especially suited to do this exercise on Linux because you set the run and build environment to any podman (or docker) container.      Set the build and run environment to our SYCL container.Refer to thefirstblog post on how to setup the build and run container.In that blog post, we named our container - 'oneapi'. It should container the SYCL compiler that webuilt and all the accompanying libraries to build our simple SYCL program.To set the build type - we need to move our cursor to the widget at the top in the center next to thehammer icon. Click on the down arrow, and then select 'Configure Project', there is a keyboard shortcut\"alt+,\" (hold alt and then comma) and the window should pop up.Select \"Default\" at the bottom of the dialog box.Under Build Environment, you want to change that from 'Host Operating System' to 'oneapi'. If 'oneapi',does not appear on your list of choices then you have not created the container using distrobox. Youshould refer to the first blog post in the series for testing.At this point, we have our build system using our container - but we aren't done yet. The problem now isthat the build system will explicitly use c++ instead of the SYCL compiler. To override using the native toolchain, we generally use an environmental variable. This is generally not recommended but for sake of simplicity, we will use it for now. In another blog post, we can revisit the issue. For the impatient, it requires that you use the native file feature of meson - see https://mesonbuild.com/Machine-files.html.For now, we will use Builder's ability to set shell environment variables to set the CXX and othercritical environment variables.Click on 'Add Variables' and set the following key value pairs (be sure to replace the paths to thecorrect paths):DPCPP_HOME=/var/home/your_login/src/dpcplusplusPATH=/usr/bin:/usr/sbin:/usr/local/bin:/home/yourlogin/bin:/home/yourlogin/.local/bin:/var/home/yourlogin/src/dpcplusplus/llvm/build/binLD_LIBRARY_PATH=/var/home/yourlogin/src/dpcplusplus/llvm/build/libCC=clangCXX=clang++Your config should look like this:The environment variables that are set are mirrored from the environment variables we had to set when we set up a simple oneapi codebase inside the container in the first blog post. We are merely recreating it.At this point, you can click on the \"hammer\" icon and GNOME Builder should proceed to properly build the source code. It will give two warnings that you can safely ignore at this point.To execute the program, you need to hit the right pointing triangle(it looks like a \"play\" button) and it will try to execute it.You'll note that it was not able to execute. That's becasue when it is running it doesn't set the LD_LIBRARY_PATHinside the container. Since build environment is using non-standard paths we have to do a trick to set everything up so that it can find the libraries it needs.So, to mitigate that we need to create a wrapper script that will set the LD_LIBRARY_PATH before executing. In another blog post, we will work on something a litte more clever. This will do for now.Let's call the script 'run-oneapi.sh'. Here is the very simple code for it:#!/bin/shexport LD_LIBRARY_PATH=\"/var/home/sri/src/dpcplusplus/llvm/build/lib\"exec /var/home/sri/Projects/oneapi-simple/bin/oneapi-simpleInstall it somewhere within your PATH environment. I have mine in ~/Projects/oneapi-simple/bin where therun time binary gets built and installed.Once you have that, you need to let builder know how to run it.The first step is to go back to the build configuration menu, use the keyboard shortcut ALT-, and then select \"Command\" on the far left column.Select \"Create Command\" and then fill in the dialog box like this:Once you've added that, you are ready to configure the run command to use this script.Click on 'Applications'On the first line you'll see \"Run Command\" which will be set to \"Automatically Discover\". Use the drop down list to select \"Run-oneapi\".Close the dialog box, and you will now have setup Builder to build and run. Since, everything is already cached. You will need to re-run the build.Select the drop down list next to the hammer icon and select \"Rebuild\". This will rebuild the source from scratch and clear out all the cache.You will now be setup to run.Click on the play icon next to the hammer icon and it should now properly build and run.Congratulations - you have now succesfully set up building an oneAPI build on GNOME Builder.There are a lot of ways to go from here. I would love to hear if anybody actually set this up and give some feedback on whether you were able to make this work and what further plans you have. There are definitely some improvements that need to be done. Since this set up doesn't actually work to ship an application.This ends third in the series. I might revisit. I would love to get feedback, improvements and whether you all are hacking code using GNOME Builder!",
            "content_html": "<p>This is the third part in the series. Part 1 is <a href=\"https://dev.to/oneapi/modern-software-development-tools-and-oneapi-part-1-40km\">here</a> and Part 2 is <a href=\"https://dev.to/oneapi/modern-software-development-tools-and-oneapi-part-2-4bjp\">here</a>.</p><p>Welcome to the third, and likely the final, post in this blog series! To recap, in the last blog post we talked about build systems particularly <a href=\"https://mesonbuild.com/\">meson</a> Before that, we talked about building a container that contains the pure open source elements of the oneAPI developer environment and use it to build a simple oneAPI SYCL program.</p><p>In this post, we're going to take our key learnings from the last two blog posts and use them to build a true user-friendly experience where you can write code using a modern IDE and compile and run them inside a container like you might be used to on other platforms like Windows and MacOS.</p><p>First, allow us to introduce you to this modern IDE - 'GNOME Builder'. <a href=\"https://apps.gnome.org/app/org.gnome.Builder/\">GNOME Builder</a> is an IDE developed for <a href=\"https://www.gnome.org/\">GNOME</a> desktop. It is integrated to be able to write GNOME and GTK applications easily with all the modern features one would expect from a IDE, and then some.</p><p>It has an impressive set of features - the author, Christian Hergert, wrote it because he was [frustrated (<a href=\"https://foundation.gnome.org/2015/01/09/interview-with-christian-hergert-about-builder-an-ide-for-gnome-2/\">https://foundation.gnome.org/2015/01/09/interview-with-christian-hergert-about-builder-an-ide-for-gnome-2/</a>)  with the state of IDEs on the Linux platform. GNOME Builder is not just an IDE, but a complete showcase of what a non-trivial application written in GNOME can do.</p><p>This blog post is about oneAPI - why use an IDE that is optimized for using GNOME to build applications?</p><p>Great question. The desktop ecosystem (GNOME and <a href=\"https://kde.org/\">KDE</a> has been focused on distribution of apps through a container technology called <a href=\"https://flatpak.org\">flatpak</a>. Flatpak allows you to have an runtime that contains everything to run a GNOME (or KDE) application. There is an associated SDK that contains all the tools needed to build the application. GNOME Builder is the first IDE that integrates this idea of containerized applications into the user experience. With Builder, you only need the application - you don't need a compiler, profiler, or development libraries - it integrates all that inside a container. This means that you don't need to think about how to setup a developer environment for any GNOME application.</p><p>The containers in the past have been flatpak based containers. But it turns out that you can leverage GNOME Builder to use any container created by podman, toolbox, or distrobox.</p><p>In essence, the first blog post in this series mimicked what flatpak already does: which is a container that contains everything you need to build an oneAPI application/program instead of a GNOME one.</p><p>In a bit of circularity that you might find amusing - we will use flatpak to get the application and then use another comtainer to build our sample application that uses Meson.</p><p>If you have not read the first two blog posts, this might be a good time to stop and read those first because we'll be using the container we created in the first blog post and the build system we used in the second blog post. It's also important  you  use a distro like Fedora or openSUSE that supports flatpak out of the box.</p><p>With the pre-requisites out of the way, let's first start by installing GNOME Builder. You can use any desktop you want, but I will be using GNOME here as it is what I usually run, please translate accordingly.</p><p>Here are the steps:</p><ul><li>First make sure you add the flathub flatpak respository:</li></ul><p><code>$  flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo</code><br /></p><ul><li>Install GNOME Builder:</li></ul><p><code>$ flatpak install flathub org.gnome.Builder</code><br /></p><ul><li>Run GNOME builder either through your desktop launch options. For GNOME, hit the meta key (usually Windows key) and then type in \"Builder\" - GNOME Builder should be your first,  and likely only, option. You can also run it from the command line:,</li></ul><p><code>$ flatpak run org.gnome.Builder</code><br /></p><p>You should now have GNOME Builder running on your machine!</p><h2>      Creating a Project</h2><p>The first step is to create a project.</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--AbJZDlQG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pqle4qghdklomilmrz04.png\"><img alt=\"Image description\" height=\"723\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--AbJZDlQG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pqle4qghdklomilmrz04.png\" width=\"880\" /></a></p><p>Select \"Create New Project...\" </p><p>You will be presented with a new screen where you put in the details for the project. Let's call our project \"oneapi-simple\".</p><p>Next we need to select the application-id. Application-ids are generally a reverse DNS type of string usually based on a hostname. I have my own domain, so I usually use that. But you can use whateer you like. In this case, I am going to use me.ramkrishna.oneapisimple.</p><p>We want to use C++, so under Language change it to C++. Note that the Template section has now changed to 'Command Line Tool' Which is exactly what we want.</p><p>Here is a filled-out screenshot of the window from Builder:</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--X-xgaUOr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dx974pybl1jmypllto76.png\"><img alt=\"Image description\" height=\"728\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--X-xgaUOr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dx974pybl1jmypllto76.png\" width=\"880\" /></a></p><p>We now create the project! Selected the \"Create Project\" and we are now ready to continue.</p><p>GNOME Builder has two sections - the sidebar and the main editor window. The side bar will have our files and so click on \"src\" and you should see two files - main.cpp and meson.buid.</p><h2>      Setup the build system</h2><p>You will notice that the project is already set up to use meson by default. Meson is the preferred build system for GNOME. Meson was created by someone from the GNOME community and thus is already well trusted. <br />In the application space, meson has proven to be quite popular replacement for autotools.</p><p>Let's leave main.cpp alone for now, and focus on meson.build. If you click on meson.build, you'll see that it looks like this:<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>oneapi_simple_sources = [  'main.cpp',]oneapi_simple_deps = []executable('oneapi-simple', oneapi_simple_sources,  dependencies: oneapi_simple_deps,  install: true,)</code></pre></div><p>This meson.build is set up to compile a generic project with the g++ compiler. So that's not going to work. If you read the previous blog post, we went through what we would need to make it work with the SYCL compiler.</p><p>Replace the contents of meson.build with this:<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>simple_oneapi_sources = files('main.cpp')simple_oneapi_deps = []executable('simple-oneapi', simple_oneapi_sources,  link_args:'-fsycl',  cpp_args:'-fsycl',  dependencies: simple_oneapi_deps,  install: true, install_dir: '/var/home/sri/Projects/oneapi-simple/bin')</code></pre></div><p>For the SYCL compiler, we need some extra linker flags. We're actually missing something even more important and that's the setup for the compiler itself!</p><p>Click on the 'meson.build' file in the top level - which should be right next to the 'COPYING' file. You'll notice that every time you open a new file, it creates a new tab in the editor view. You can easily switch to each file by clicking on the tab.</p><p>Let's take a look at it. It should look like this.<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>project('oneapi-simple', ['cpp', 'c'],          version: '0.1.0',    meson_version: '&gt;= 0.59.0',  default_options: [ 'warning_level=2', 'werror=false', 'cpp_std=gnu++2a', ],)subdir('src')</code></pre></div><p>The important part here is that we are identifying that this project is C++. All of this is correct and there is nothing more to be done.</p><h2>      Set up our source</h2><p>Now, that we have the build set up. It's time to replace the code in main.cpp. Currently, the code looks like:<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>#include &lt;iostream&gt;int main() {    std::cout &lt;&lt; \"Hello World\\n\";    return 0;}</code></pre></div><p>We are going to replace it with:<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>#include &lt;sycl/sycl.hpp&gt;int main() {  // Creating buffer of 4 ints to be used inside the kernel code  sycl::buffer&lt;sycl::cl_int, 1&gt; Buffer(4);  // Creating SYCL queue  sycl::queue Queue;  // Size of index space for kernel  sycl::range&lt;1&gt; NumOfWorkItems{Buffer.size()};  // Submitting command group(work) to queue  Queue.submit([&amp;](sycl::handler &amp;cgh) {    // Getting write only access to the buffer on a device    auto Accessor = Buffer.get_access&lt;sycl::access::mode::write&gt;(cgh);    // Executing kernel    cgh.parallel_for&lt;class FillBuffer&gt;(        NumOfWorkItems, [=](sycl::id&lt;1&gt; WIid) {          // Fill buffer with indexes          Accessor[WIid] = (sycl::cl_int)WIid.get(0);        });  });  // Getting read only access to the buffer on the host.  // Implicit barrier waiting for queue to complete the work.  const auto HostAccessor = Buffer.get_access&lt;sycl::access::mode::read&gt;();  // Check the results  bool MismatchFound = false;  for (size_t I = 0; I &lt; Buffer.size(); ++I) {    if (HostAccessor[I] != I) {      std::cout &lt;&lt; \"The result is incorrect for element: \" &lt;&lt; I                &lt;&lt; \" , expected: \" &lt;&lt; I &lt;&lt; \" , got: \" &lt;&lt; HostAccessor[I]                &lt;&lt; std::endl;      MismatchFound = true;    }  }  if (!MismatchFound) {    std::cout &lt;&lt; \"The results are correct!\" &lt;&lt; std::endl;  }  return MismatchFound;}</code></pre></div><p>OK - now we have everything. But we can't quite compile yet. Right now, if you tried to compile this - it won't work. The reason is, the build is currently set up for native build'. Which means it will try to use the toolchain on the host system. On the host system, we don't have any of the oneAPI libraries or the SYCL compiler. So it won't find anything. Everything we wanted is encapsulated in a container.</p><p>This is why GNOME Builder is especially suited to do this exercise on Linux because you set the run and build environment to any podman (or docker) container.</p><h2>      Set the build and run environment to our SYCL container.</h2><p>Refer to the<br /><a href=\"https://dev.to/oneapi/modern-software-development-tools-and-oneapi-part-1-40km\">first</a><br />blog post on how to setup the build and run container.</p><p>In that blog post, we named our container - 'oneapi'. It should container the SYCL compiler that we<br />built and all the accompanying libraries to build our simple SYCL program.</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--f-dAEe_z--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/clukhlkv1bb36bmbet59.png\"><img alt=\"Image description\" height=\"616\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--f-dAEe_z--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/clukhlkv1bb36bmbet59.png\" width=\"880\" /></a></p><p>To set the build type - we need to move our cursor to the widget at the top in the center next to the<br />hammer icon. Click on the down arrow, and then select 'Configure Project', there is a keyboard shortcut<br />\"alt+,\" (hold alt and then comma) and the window should pop up.</p><p>Select \"Default\" at the bottom of the dialog box.</p><p>Under Build Environment, you want to change that from 'Host Operating System' to 'oneapi'. If 'oneapi',<br />does not appear on your list of choices then you have not created the container using distrobox. You<br />should refer to the first blog post in the series for testing.</p><p>At this point, we have our build system using our container - but we aren't done yet. The problem now is<br />that the build system will explicitly use c++ instead of the SYCL compiler. To override using the native toolchain, we generally use an environmental variable. This is generally not recommended but for sake of simplicity, we will use it for now. In another blog post, we can revisit the issue. For the impatient, it requires that you use the native file feature of meson - see <a href=\"https://mesonbuild.com/Machine-files.html\">https://mesonbuild.com/Machine-files.html</a>.</p><p>For now, we will use Builder's ability to set shell environment variables to set the CXX and other<br />critical environment variables.</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--IN7cA_Nq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uv0t38nizjris20yn15n.png\"><img alt=\"Image description\" height=\"261\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--IN7cA_Nq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uv0t38nizjris20yn15n.png\" width=\"880\" /></a></p><p>Click on 'Add Variables' and set the following key value pairs (be sure to replace the paths to the<br />correct paths):<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight plaintext\"><code>DPCPP_HOME=/var/home/your_login/src/dpcplusplusPATH=/usr/bin:/usr/sbin:/usr/local/bin:/home/yourlogin/bin:/home/yourlogin/.local/bin:/var/home/yourlogin/src/dpcplusplus/llvm/build/binLD_LIBRARY_PATH=/var/home/yourlogin/src/dpcplusplus/llvm/build/libCC=clangCXX=clang++</code></pre></div><p>Your config should look like this:</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--WEj27cVk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hu8gd5dcfeqwplid9bfs.png\"><img alt=\"Image description\" height=\"559\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--WEj27cVk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hu8gd5dcfeqwplid9bfs.png\" width=\"880\" /></a></p><p>The environment variables that are set are mirrored from the environment variables we had to set when we set up a simple oneapi codebase inside the container in the first blog post. We are merely recreating it.</p><p>At this point, you can click on the \"hammer\" icon and GNOME Builder should proceed to properly build the source code. It will give two warnings that you can safely ignore at this point.</p><p>To execute the program, you need to hit the right pointing triangle(it looks like a \"play\" button) and it will try to execute it.</p><p>You'll note that it was not able to execute. </p><p>That's becasue when it is running it doesn't set the LD_LIBRARY_PATH<br />inside the container. Since build environment is using non-standard paths we have to do a trick to set everything up so that it can find the libraries it needs.</p><p>So, to mitigate that we need to create a wrapper script that will set the LD_LIBRARY_PATH before executing. In another blog post, we will work on something a litte more clever. This will do for now.</p><p>Let's call the script 'run-oneapi.sh'. Here is the very simple code for it:<br /></p><div class=\"highlight js-code-highlight\"><pre class=\"highlight shell\"><code><span class=\"c\">#!/bin/sh</span><span class=\"nb\">export </span><span class=\"nv\">LD_LIBRARY_PATH</span><span class=\"o\">=</span><span class=\"s2\">\"/var/home/sri/src/dpcplusplus/llvm/build/lib\"</span><span class=\"nb\">exec</span> /var/home/sri/Projects/oneapi-simple/bin/oneapi-simple</code></pre></div><p>Install it somewhere within your PATH environment. I have mine in ~/Projects/oneapi-simple/bin where the<br />run time binary gets built and installed.</p><p>Once you have that, you need to let builder know how to run it.</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--eHBmLO5f--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6zi26imjcw56opdh30cl.png\"><img alt=\"Image description\" height=\"616\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--eHBmLO5f--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6zi26imjcw56opdh30cl.png\" width=\"880\" /></a></p><p>The first step is to go back to the build configuration menu, use the keyboard shortcut ALT-, and then select \"Command\" on the far left column.</p><p>Select \"Create Command\" and then fill in the dialog box like this:</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--tPf9uj8X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dobm6erppuvh8pw03s1n.png\"><img alt=\"Image description\" height=\"880\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--tPf9uj8X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dobm6erppuvh8pw03s1n.png\" width=\"880\" /></a></p><p>Once you've added that, you are ready to configure the run command to use this script.</p><p><a class=\"article-body-image-wrapper\" href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--NmukZYYg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/v4b84d8z97wb2ni19yec.png\"><img alt=\"Image description\" height=\"616\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--NmukZYYg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/v4b84d8z97wb2ni19yec.png\" width=\"880\" /></a></p><p>Click on 'Applications'</p><p>On the first line you'll see \"Run Command\" which will be set to \"Automatically Discover\". Use the drop down list to select \"Run-oneapi\".</p><p>Close the dialog box, and you will now have setup Builder to build and run. Since, everything is already cached. You will need to re-run the build.</p><p>Select the drop down list next to the hammer icon and select \"Rebuild\". This will rebuild the source from scratch and clear out all the cache.</p><p>You will now be setup to run.</p><p>Click on the play icon next to the hammer icon and it should now properly build and run.</p><p>Congratulations - you have now succesfully set up building an oneAPI build on GNOME Builder.</p><p>There are a lot of ways to go from here. I would love to hear if anybody actually set this up and give some feedback on whether you were able to make this work and what further plans you have. </p><p>There are definitely some improvements that need to be done. Since this set up doesn't actually work to ship an application.</p><p>This ends third in the series. I might revisit. I would love to get feedback, improvements and whether you all are hacking code using GNOME Builder!</p>",
            "url": "https://hpc.social/community-blog/2023/modern-software-development-tools-and-oneapi-part-3/",
            
            
            
            
            
            "date_published": "2023-02-28T02:19:25-07:00",
            "date_modified": "2023-02-28T02:19:25-07:00",
            
                "author": "oneAPI Community Blog"
            
        }
    
    ]
}
